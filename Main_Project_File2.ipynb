{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2c025ca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "b2c025ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72090241"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Datafiniti_Womens_Shoes(1).csv')"
      ],
      "id": "72090241"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "096c48e8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "a8e4a038-fdf3-483c-e39a-15860ce2adfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id             dateAdded           dateUpdated asins  \\\n",
              "0  AVpfEf_hLJeJML431ueH  2015-05-04T12:13:08Z  2018-01-29T04:38:43Z   NaN   \n",
              "1  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   NaN   \n",
              "2  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   NaN   \n",
              "3  AVpjXyCc1cnluZ0-V-Gj  2017-01-27T01:25:56Z  2018-01-04T11:52:35Z   NaN   \n",
              "4  AVphGKLPilAPnD_x1Nrm  2017-01-27T01:25:56Z  2018-01-18T03:55:18Z   NaN   \n",
              "\n",
              "         brand                                         categories  \\\n",
              "0  Naturalizer  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "1     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "2     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "3     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "4     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "\n",
              "  primaryCategories                          colors                 dimension  \\\n",
              "0             Shoes  Silver,Cream Watercolor Floral                       NaN   \n",
              "1             Shoes                            Grey                       NaN   \n",
              "2             Shoes                            Grey                       NaN   \n",
              "3       Shoes,Shoes                           Black  6.0 in x 6.0 in x 1.0 in   \n",
              "4             Shoes                            Grey  6.0 in x 6.0 in x 1.0 in   \n",
              "\n",
              "            ean  ...   prices.merchant prices.offer prices.returnPolicy  \\\n",
              "0           NaN  ...     Overstock.com          NaN                 NaN   \n",
              "1  3.397705e+10  ...       Walmart.com          NaN                 NaN   \n",
              "2  3.397705e+10  ...  Slippers Dot Com          NaN                 NaN   \n",
              "3  3.397705e+10  ...  Slippers Dot Com          NaN                 NaN   \n",
              "4  3.397705e+10  ...       Walmart.com          NaN                 NaN   \n",
              "\n",
              "  prices.shipping prices.size  \\\n",
              "0             NaN           S   \n",
              "1        Standard           6   \n",
              "2           Value           6   \n",
              "3           Value           6   \n",
              "4       Expedited           6   \n",
              "\n",
              "                                   prices.sourceURLs  \\\n",
              "0  https://www.overstock.com/Clothing-Shoes/Women...   \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "\n",
              "                                               sizes  \\\n",
              "0  6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...   \n",
              "1                                         10,7,6,9,8   \n",
              "2                                         10,7,6,9,8   \n",
              "3                                         10,7,6,9,8   \n",
              "4                                         10,7,6,9,8   \n",
              "\n",
              "                                          sourceURLs           upc weight  \n",
              "0  https://www.walmart.com/ip/Naturalizer-Danya-W...  017136472311    NaN  \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743    NaN  \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743    NaN  \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045903    NaN  \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045958    NaN  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f031e9f2-31dd-4a5b-aa28-d1ee646622b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>colors</th>\n",
              "      <th>dimension</th>\n",
              "      <th>ean</th>\n",
              "      <th>...</th>\n",
              "      <th>prices.merchant</th>\n",
              "      <th>prices.offer</th>\n",
              "      <th>prices.returnPolicy</th>\n",
              "      <th>prices.shipping</th>\n",
              "      <th>prices.size</th>\n",
              "      <th>prices.sourceURLs</th>\n",
              "      <th>sizes</th>\n",
              "      <th>sourceURLs</th>\n",
              "      <th>upc</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpfEf_hLJeJML431ueH</td>\n",
              "      <td>2015-05-04T12:13:08Z</td>\n",
              "      <td>2018-01-29T04:38:43Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>Silver,Cream Watercolor Floral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Overstock.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>https://www.overstock.com/Clothing-Shoes/Women...</td>\n",
              "      <td>6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...</td>\n",
              "      <td>https://www.walmart.com/ip/Naturalizer-Danya-W...</td>\n",
              "      <td>017136472311</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>Grey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.397705e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>Walmart.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Standard</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>Grey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.397705e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>Slippers Dot Com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpjXyCc1cnluZ0-V-Gj</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-04T11:52:35Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes,Shoes</td>\n",
              "      <td>Black</td>\n",
              "      <td>6.0 in x 6.0 in x 1.0 in</td>\n",
              "      <td>3.397705e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>Slippers Dot Com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Value</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045903</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVphGKLPilAPnD_x1Nrm</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-18T03:55:18Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>Grey</td>\n",
              "      <td>6.0 in x 6.0 in x 1.0 in</td>\n",
              "      <td>3.397705e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>Walmart.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Expedited</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045958</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f031e9f2-31dd-4a5b-aa28-d1ee646622b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f031e9f2-31dd-4a5b-aa28-d1ee646622b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f031e9f2-31dd-4a5b-aa28-d1ee646622b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "096c48e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "766df273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f03179-2b88-4d93-f7bf-6624609f8452"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ],
      "id": "766df273"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d998a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d62b02-8c58-4948-9019-0f8bada84f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 34 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   id                   10000 non-null  object \n",
            " 1   dateAdded            10000 non-null  object \n",
            " 2   dateUpdated          10000 non-null  object \n",
            " 3   asins                3 non-null      object \n",
            " 4   brand                10000 non-null  object \n",
            " 5   categories           10000 non-null  object \n",
            " 6   primaryCategories    10000 non-null  object \n",
            " 7   colors               2631 non-null   object \n",
            " 8   dimension            117 non-null    object \n",
            " 9   ean                  671 non-null    float64\n",
            " 10  imageURLs            10000 non-null  object \n",
            " 11  keys                 10000 non-null  object \n",
            " 12  manufacturer         527 non-null    object \n",
            " 13  manufacturerNumber   2482 non-null   object \n",
            " 14  name                 10000 non-null  object \n",
            " 15  prices.amountMax     10000 non-null  float64\n",
            " 16  prices.amountMin     10000 non-null  float64\n",
            " 17  prices.availability  434 non-null    object \n",
            " 18  prices.color         10000 non-null  object \n",
            " 19  prices.condition     438 non-null    object \n",
            " 20  prices.currency      10000 non-null  object \n",
            " 21  prices.dateAdded     9223 non-null   object \n",
            " 22  prices.dateSeen      10000 non-null  object \n",
            " 23  prices.isSale        10000 non-null  bool   \n",
            " 24  prices.merchant      435 non-null    object \n",
            " 25  prices.offer         121 non-null    object \n",
            " 26  prices.returnPolicy  0 non-null      float64\n",
            " 27  prices.shipping      412 non-null    object \n",
            " 28  prices.size          10000 non-null  object \n",
            " 29  prices.sourceURLs    10000 non-null  object \n",
            " 30  sizes                10000 non-null  object \n",
            " 31  sourceURLs           10000 non-null  object \n",
            " 32  upc                  9640 non-null   object \n",
            " 33  weight               299 non-null    object \n",
            "dtypes: bool(1), float64(4), object(29)\n",
            "memory usage: 2.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ],
      "id": "5d998a24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "976b72da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30da07ad-e05f-47ec-b20a-70bfee220333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'dateAdded', 'dateUpdated', 'asins', 'brand', 'categories',\n",
              "       'primaryCategories', 'colors', 'dimension', 'ean', 'imageURLs', 'keys',\n",
              "       'manufacturer', 'manufacturerNumber', 'name', 'prices.amountMax',\n",
              "       'prices.amountMin', 'prices.availability', 'prices.color',\n",
              "       'prices.condition', 'prices.currency', 'prices.dateAdded',\n",
              "       'prices.dateSeen', 'prices.isSale', 'prices.merchant', 'prices.offer',\n",
              "       'prices.returnPolicy', 'prices.shipping', 'prices.size',\n",
              "       'prices.sourceURLs', 'sizes', 'sourceURLs', 'upc', 'weight'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.columns"
      ],
      "id": "976b72da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6f45d72"
      },
      "source": [
        "## Data Preprocessing"
      ],
      "id": "c6f45d72"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15829694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0398ff83-65e4-431e-e1ba-2cfdebfbce2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'dateadded', 'dateupdated', 'asins', 'brand', 'categories',\n",
              "       'primarycategories', 'colors', 'dimension', 'ean', 'imageurls', 'keys',\n",
              "       'manufacturer', 'manufacturernumber', 'name', 'prices.amountmax',\n",
              "       'prices.amountmin', 'prices.availability', 'prices.color',\n",
              "       'prices.condition', 'prices.currency', 'prices.dateadded',\n",
              "       'prices.dateseen', 'prices.issale', 'prices.merchant', 'prices.offer',\n",
              "       'prices.returnpolicy', 'prices.shipping', 'prices.size',\n",
              "       'prices.sourceurls', 'sizes', 'sourceurls', 'upc', 'weight'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Converting every column name to lowercase\n",
        "df.columns = map(str.lower, df.columns)\n",
        "df.columns"
      ],
      "id": "15829694"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83ae90c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c162836-c7a2-4177-c669-dd79da2a2c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         0\n",
              "dateadded                  0\n",
              "dateupdated                0\n",
              "asins                   9997\n",
              "brand                      0\n",
              "categories                 0\n",
              "primarycategories          0\n",
              "colors                  7369\n",
              "dimension               9883\n",
              "ean                     9329\n",
              "imageurls                  0\n",
              "keys                       0\n",
              "manufacturer            9473\n",
              "manufacturernumber      7518\n",
              "name                       0\n",
              "prices.amountmax           0\n",
              "prices.amountmin           0\n",
              "prices.availability     9566\n",
              "prices.color               0\n",
              "prices.condition        9562\n",
              "prices.currency            0\n",
              "prices.dateadded         777\n",
              "prices.dateseen            0\n",
              "prices.issale              0\n",
              "prices.merchant         9565\n",
              "prices.offer            9879\n",
              "prices.returnpolicy    10000\n",
              "prices.shipping         9588\n",
              "prices.size                0\n",
              "prices.sourceurls          0\n",
              "sizes                      0\n",
              "sourceurls                 0\n",
              "upc                      360\n",
              "weight                  9701\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.isna().sum()"
      ],
      "id": "b83ae90c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a7884fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1628e5ed-e7b4-45bb-ee23-1d48c2d809a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             num_nulls  ratio_of_null\n",
              "id                   0         0.0000\n",
              "dateadded            0         0.0000\n",
              "dateupdated          0         0.0000\n",
              "asins             9997         0.9997\n",
              "brand                0         0.0000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f07c38be-c3cc-4962-82f6-a1f9ebe43da4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_nulls</th>\n",
              "      <th>ratio_of_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dateadded</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dateupdated</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>asins</th>\n",
              "      <td>9997</td>\n",
              "      <td>0.9997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brand</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f07c38be-c3cc-4962-82f6-a1f9ebe43da4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f07c38be-c3cc-4962-82f6-a1f9ebe43da4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f07c38be-c3cc-4962-82f6-a1f9ebe43da4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# The ratio of null values\n",
        "df_null_table = pd.DataFrame(df.isnull().sum(axis=0),columns=['num_nulls'])\n",
        "df_null_table['ratio_of_null'] = df_null_table['num_nulls']/df.shape[0]\n",
        "df_null_table.head()"
      ],
      "id": "6a7884fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb41f496"
      },
      "source": [
        "We are going to remove all the columns that have more than 50% null values"
      ],
      "id": "eb41f496"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a53a363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47229916-69f3-49ec-d6f6-730301b2b658"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['asins', 'colors', 'dimension', 'ean', 'manufacturer',\n",
              "       'manufacturernumber', 'prices.availability', 'prices.condition',\n",
              "       'prices.merchant', 'prices.offer', 'prices.returnpolicy',\n",
              "       'prices.shipping', 'weight'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "col_to_remove = df_null_table[df_null_table['ratio_of_null']>0.5].index\n",
        "col_to_remove"
      ],
      "id": "2a53a363"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92731f2f"
      },
      "outputs": [],
      "source": [
        "df_after_removal = df[[col for col in df.columns if col not in col_to_remove]]"
      ],
      "id": "92731f2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d87d8d0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74772748-d79e-4856-d23d-0994c362094c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data shape before (10000, 34) and after removal (10000, 21)\n"
          ]
        }
      ],
      "source": [
        "print(f\"The data shape before {df.shape} and after removal {df_after_removal.shape}\")"
      ],
      "id": "d87d8d0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e52360a"
      },
      "source": [
        "## Dealing with the other null values"
      ],
      "id": "0e52360a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05b53600"
      },
      "outputs": [],
      "source": [
        "df = df_after_removal"
      ],
      "id": "05b53600"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "915fcd03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720d996f-619c-413f-878c-0c511cc10e4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                     0\n",
              "dateadded              0\n",
              "dateupdated            0\n",
              "brand                  0\n",
              "categories             0\n",
              "primarycategories      0\n",
              "imageurls              0\n",
              "keys                   0\n",
              "name                   0\n",
              "prices.amountmax       0\n",
              "prices.amountmin       0\n",
              "prices.color           0\n",
              "prices.currency        0\n",
              "prices.dateadded     777\n",
              "prices.dateseen        0\n",
              "prices.issale          0\n",
              "prices.size            0\n",
              "prices.sourceurls      0\n",
              "sizes                  0\n",
              "sourceurls             0\n",
              "upc                  360\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.isna().sum()"
      ],
      "id": "915fcd03"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec6df93f"
      },
      "outputs": [],
      "source": [
        "for item in ['prices.dateadded','upc']:\n",
        "    df[item] = df[item].fillna(df[item].mode()[0])"
      ],
      "id": "ec6df93f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41e2add8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd309d6-e40c-4a33-fdce-1754a0150214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                   0\n",
              "dateadded            0\n",
              "dateupdated          0\n",
              "brand                0\n",
              "categories           0\n",
              "primarycategories    0\n",
              "imageurls            0\n",
              "keys                 0\n",
              "name                 0\n",
              "prices.amountmax     0\n",
              "prices.amountmin     0\n",
              "prices.color         0\n",
              "prices.currency      0\n",
              "prices.dateadded     0\n",
              "prices.dateseen      0\n",
              "prices.issale        0\n",
              "prices.size          0\n",
              "prices.sourceurls    0\n",
              "sizes                0\n",
              "sourceurls           0\n",
              "upc                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.isna().sum()"
      ],
      "id": "41e2add8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a051ab3d"
      },
      "source": [
        "### creating a new column"
      ],
      "id": "a051ab3d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "092e09f1"
      },
      "outputs": [],
      "source": [
        "#Let's create a new column call prices.amountavg by taking the average of prices.amountmax and prices.amountmin\n",
        "df['prices.amountavg'] = (df['prices.amountmin'] + df['prices.amountmax'])/2"
      ],
      "id": "092e09f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f3628d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a28b6fd3-40ef-441c-e649-4487e398a769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   prices.amountmin  prices.amountmax  prices.amountavg\n",
              "0             55.99             55.99            55.990\n",
              "1             35.25             47.00            41.125\n",
              "2             35.25             35.25            35.250\n",
              "3             24.75             24.75            24.750\n",
              "4             30.39             33.00            31.695\n",
              "5              7.90             14.00            10.950\n",
              "6             12.79             24.00            18.395\n",
              "7             12.79             24.00            18.395\n",
              "8             39.88             59.00            49.440\n",
              "9             47.99             59.00            53.495"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcc69312-a814-4e7a-a00f-e2b017ba976d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prices.amountmin</th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>prices.amountavg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.99</td>\n",
              "      <td>55.99</td>\n",
              "      <td>55.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35.25</td>\n",
              "      <td>47.00</td>\n",
              "      <td>41.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.25</td>\n",
              "      <td>35.25</td>\n",
              "      <td>35.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.75</td>\n",
              "      <td>24.75</td>\n",
              "      <td>24.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.39</td>\n",
              "      <td>33.00</td>\n",
              "      <td>31.695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.90</td>\n",
              "      <td>14.00</td>\n",
              "      <td>10.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12.79</td>\n",
              "      <td>24.00</td>\n",
              "      <td>18.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12.79</td>\n",
              "      <td>24.00</td>\n",
              "      <td>18.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>39.88</td>\n",
              "      <td>59.00</td>\n",
              "      <td>49.440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>47.99</td>\n",
              "      <td>59.00</td>\n",
              "      <td>53.495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcc69312-a814-4e7a-a00f-e2b017ba976d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcc69312-a814-4e7a-a00f-e2b017ba976d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcc69312-a814-4e7a-a00f-e2b017ba976d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df[['prices.amountmin','prices.amountmax','prices.amountavg']].head(10)"
      ],
      "id": "8f3628d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cad5b0a"
      },
      "source": [
        "### Adding price.stat column"
      ],
      "id": "0cad5b0a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ce534c9"
      },
      "source": [
        "We are creating a new column \"prices.stat\" that contains boolean value \"True\" if the price is over 100 or \"False\" if the price is under 100"
      ],
      "id": "5ce534c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8990620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "1fbee0a8-e11a-4bfb-f840-8690d4514ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id             dateadded           dateupdated  \\\n",
              "0  AVpfEf_hLJeJML431ueH  2015-05-04T12:13:08Z  2018-01-29T04:38:43Z   \n",
              "1  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   \n",
              "2  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   \n",
              "3  AVpjXyCc1cnluZ0-V-Gj  2017-01-27T01:25:56Z  2018-01-04T11:52:35Z   \n",
              "4  AVphGKLPilAPnD_x1Nrm  2017-01-27T01:25:56Z  2018-01-18T03:55:18Z   \n",
              "\n",
              "         brand                                         categories  \\\n",
              "0  Naturalizer  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "1     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "2     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "3     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "4     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "\n",
              "  primarycategories                                          imageurls  \\\n",
              "0             Shoes  https://i5.walmartimages.com/asr/861ca6cf-fa55...   \n",
              "1             Shoes  https://i5.walmartimages.com/asr/421de5d5-3a74...   \n",
              "2             Shoes  https://i5.walmartimages.com/asr/421de5d5-3a74...   \n",
              "3       Shoes,Shoes  https://i5.walmartimages.com/asr/950d38a5-0113...   \n",
              "4             Shoes  https://i5.walmartimages.com/asr/5e137bc3-c900...   \n",
              "\n",
              "                                                keys  \\\n",
              "0  naturalizer/47147sc022,017136472311,womensnatu...   \n",
              "1  mukluks/00173650206,033977045743,muklukswomens...   \n",
              "2  mukluks/00173650206,033977045743,muklukswomens...   \n",
              "3  033977045903,muklukswomensdawnsuedescuffslippe...   \n",
              "4  mukluks/00173660206,033977045958,0033977045958...   \n",
              "\n",
              "                                                name  prices.amountmax  ...  \\\n",
              "0  Naturalizer Danya Women N/S Open Toe Synthetic...             55.99  ...   \n",
              "1                MUK LUKS Womens Jane Suede Moccasin             47.00  ...   \n",
              "2                MUK LUKS Womens Jane Suede Moccasin             35.25  ...   \n",
              "3           MUK LUKS Womens Dawn Suede Scuff Slipper             24.75  ...   \n",
              "4           MUK LUKS Womens Dawn Suede Scuff Slipper             33.00  ...   \n",
              "\n",
              "       prices.dateadded                                    prices.dateseen  \\\n",
              "0  2017-03-28T11:40:25Z  2017-03-25T09:19:24.819Z,2017-03-25T09:19:19.600Z   \n",
              "1  2018-01-03T05:21:54Z  2017-12-08T14:24:00.000Z,2017-11-01T02:52:00.000Z   \n",
              "2  2017-12-06T05:02:42Z  2017-11-10T15:11:00.000Z,2017-11-18T08:00:00.000Z   \n",
              "3  2018-01-04T11:52:35Z                           2017-12-07T16:37:00.000Z   \n",
              "4  2017-12-04T21:35:47Z                           2017-11-17T21:15:00.000Z   \n",
              "\n",
              "  prices.issale prices.size  \\\n",
              "0         False           S   \n",
              "1          True           6   \n",
              "2         False           6   \n",
              "3         False           6   \n",
              "4          True           6   \n",
              "\n",
              "                                   prices.sourceurls  \\\n",
              "0  https://www.overstock.com/Clothing-Shoes/Women...   \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "\n",
              "                                               sizes  \\\n",
              "0  6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...   \n",
              "1                                         10,7,6,9,8   \n",
              "2                                         10,7,6,9,8   \n",
              "3                                         10,7,6,9,8   \n",
              "4                                         10,7,6,9,8   \n",
              "\n",
              "                                          sourceurls           upc  \\\n",
              "0  https://www.walmart.com/ip/Naturalizer-Danya-W...  017136472311   \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743   \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743   \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045903   \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045958   \n",
              "\n",
              "  prices.amountavg price.stat  \n",
              "0           55.990      False  \n",
              "1           41.125      False  \n",
              "2           35.250      False  \n",
              "3           24.750      False  \n",
              "4           31.695      False  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e52f2291-298f-4982-9534-cba11cede170\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateadded</th>\n",
              "      <th>dateupdated</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primarycategories</th>\n",
              "      <th>imageurls</th>\n",
              "      <th>keys</th>\n",
              "      <th>name</th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>...</th>\n",
              "      <th>prices.dateadded</th>\n",
              "      <th>prices.dateseen</th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>prices.size</th>\n",
              "      <th>prices.sourceurls</th>\n",
              "      <th>sizes</th>\n",
              "      <th>sourceurls</th>\n",
              "      <th>upc</th>\n",
              "      <th>prices.amountavg</th>\n",
              "      <th>price.stat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpfEf_hLJeJML431ueH</td>\n",
              "      <td>2015-05-04T12:13:08Z</td>\n",
              "      <td>2018-01-29T04:38:43Z</td>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/861ca6cf-fa55...</td>\n",
              "      <td>naturalizer/47147sc022,017136472311,womensnatu...</td>\n",
              "      <td>Naturalizer Danya Women N/S Open Toe Synthetic...</td>\n",
              "      <td>55.99</td>\n",
              "      <td>...</td>\n",
              "      <td>2017-03-28T11:40:25Z</td>\n",
              "      <td>2017-03-25T09:19:24.819Z,2017-03-25T09:19:19.600Z</td>\n",
              "      <td>False</td>\n",
              "      <td>S</td>\n",
              "      <td>https://www.overstock.com/Clothing-Shoes/Women...</td>\n",
              "      <td>6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...</td>\n",
              "      <td>https://www.walmart.com/ip/Naturalizer-Danya-W...</td>\n",
              "      <td>017136472311</td>\n",
              "      <td>55.990</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/421de5d5-3a74...</td>\n",
              "      <td>mukluks/00173650206,033977045743,muklukswomens...</td>\n",
              "      <td>MUK LUKS Womens Jane Suede Moccasin</td>\n",
              "      <td>47.00</td>\n",
              "      <td>...</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>2017-12-08T14:24:00.000Z,2017-11-01T02:52:00.000Z</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>41.125</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/421de5d5-3a74...</td>\n",
              "      <td>mukluks/00173650206,033977045743,muklukswomens...</td>\n",
              "      <td>MUK LUKS Womens Jane Suede Moccasin</td>\n",
              "      <td>35.25</td>\n",
              "      <td>...</td>\n",
              "      <td>2017-12-06T05:02:42Z</td>\n",
              "      <td>2017-11-10T15:11:00.000Z,2017-11-18T08:00:00.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>35.250</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpjXyCc1cnluZ0-V-Gj</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-04T11:52:35Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes,Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/950d38a5-0113...</td>\n",
              "      <td>033977045903,muklukswomensdawnsuedescuffslippe...</td>\n",
              "      <td>MUK LUKS Womens Dawn Suede Scuff Slipper</td>\n",
              "      <td>24.75</td>\n",
              "      <td>...</td>\n",
              "      <td>2018-01-04T11:52:35Z</td>\n",
              "      <td>2017-12-07T16:37:00.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045903</td>\n",
              "      <td>24.750</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVphGKLPilAPnD_x1Nrm</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-18T03:55:18Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/5e137bc3-c900...</td>\n",
              "      <td>mukluks/00173660206,033977045958,0033977045958...</td>\n",
              "      <td>MUK LUKS Womens Dawn Suede Scuff Slipper</td>\n",
              "      <td>33.00</td>\n",
              "      <td>...</td>\n",
              "      <td>2017-12-04T21:35:47Z</td>\n",
              "      <td>2017-11-17T21:15:00.000Z</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045958</td>\n",
              "      <td>31.695</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e52f2291-298f-4982-9534-cba11cede170')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e52f2291-298f-4982-9534-cba11cede170 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e52f2291-298f-4982-9534-cba11cede170');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#creating a new column with boolean values.Shoes priced over $100 is expensive,under 100 is affordable.\n",
        "df['price.stat']=(df['prices.amountmax']>100)\n",
        "df.head()"
      ],
      "id": "d8990620"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0af40c1"
      },
      "source": [
        "### Adding a new column brand.count"
      ],
      "id": "f0af40c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23801e08"
      },
      "source": [
        "Lets add one more new column named brand.count\n",
        "This column shows the number of shoes that each brand sold\n"
      ],
      "id": "23801e08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7917dfd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a7d340b0-571e-4984-e92e-5a4c4bd81e79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            brand  brand.count\n",
              "0     Naturalizer            1\n",
              "1        MUK LUKS           18\n",
              "2        MUK LUKS           18\n",
              "3        MUK LUKS           18\n",
              "4        MUK LUKS           18\n",
              "...           ...          ...\n",
              "9995        Asics           19\n",
              "9996        Asics           19\n",
              "9997       Kaanas            1\n",
              "9998         Nike          179\n",
              "9999     OTZShoes            1\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26f884c4-ce76-4a15-abce-cd8263819767\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>brand.count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Asics</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Asics</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Kaanas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Nike</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>OTZShoes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26f884c4-ce76-4a15-abce-cd8263819767')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26f884c4-ce76-4a15-abce-cd8263819767 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26f884c4-ce76-4a15-abce-cd8263819767');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# New column brand.count \n",
        "\n",
        "df['brand.count'] = df['brand'].map(df['brand'].value_counts())\n",
        "df[['brand','brand.count']]"
      ],
      "id": "7917dfd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d1b6b2b"
      },
      "outputs": [],
      "source": [
        "affordable = df.sort_values('prices.amountmax')\n",
        "affordable = affordable[['brand', 'prices.amountmax']].groupby('brand').agg(min)<100"
      ],
      "id": "9d1b6b2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7087938f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "b43900bc-6bd4-4ee3-b4be-5d1a210784db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                prices.amountmax\n",
              "brand                           \n",
              "2 lips too                  True\n",
              "Adidas                     False\n",
              "Adidas Outdoor              True\n",
              "Altra                       True\n",
              "Arc'teryx                  False\n",
              "Asics                       True\n",
              "Astral                      True\n",
              "Birkenstock                False\n",
              "Bogs                        True\n",
              "Brinley Co.                 True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed39494d-a56e-42ac-ac04-7925a976fabf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prices.amountmax</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brand</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2 lips too</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adidas</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adidas Outdoor</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Altra</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arc'teryx</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Asics</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Astral</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Birkenstock</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bogs</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Brinley Co.</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed39494d-a56e-42ac-ac04-7925a976fabf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed39494d-a56e-42ac-ac04-7925a976fabf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed39494d-a56e-42ac-ac04-7925a976fabf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "affordable.head(10)"
      ],
      "id": "7087938f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffef4f1e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a0835397-250f-4eb8-d30c-b0febb8b3968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               prices.amountmax                 prices.amountmin          \\\n",
              "                            min  median     max              min  median   \n",
              "brand                                                                      \n",
              "2 lips too                64.95   64.95   79.99            39.99   49.99   \n",
              "Adidas                   109.95  129.95  159.95            76.96   84.47   \n",
              "Adidas Outdoor            99.95   99.95  119.95            99.95   99.95   \n",
              "Altra                     99.95  129.95  149.95            76.96  112.46   \n",
              "Arc'teryx                170.00  170.00  170.00           110.50  110.50   \n",
              "\n",
              "                       prices.issale               prices.amountavg           \\\n",
              "                   max           min median    max              min   median   \n",
              "brand                                                                          \n",
              "2 lips too       79.99         False    0.0  False           52.470   57.470   \n",
              "Adidas          159.95         False    1.0   True           93.455  110.455   \n",
              "Adidas Outdoor  119.95         False    0.0  False           99.950   99.950   \n",
              "Altra           149.95         False    0.0   True           93.455  129.950   \n",
              "Arc'teryx       170.00         False    1.0   True          140.250  140.250   \n",
              "\n",
              "                       price.stat               brand.count             \n",
              "                   max        min median    max         min median max  \n",
              "brand                                                                   \n",
              "2 lips too       79.99      False    0.0  False          19   19.0  19  \n",
              "Adidas          159.95       True    1.0   True          21   21.0  21  \n",
              "Adidas Outdoor  119.95      False    0.0   True           5    5.0   5  \n",
              "Altra           149.95      False    1.0   True          21   21.0  21  \n",
              "Arc'teryx       170.00       True    1.0   True           3    3.0   3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf6dafe8-0d64-4530-8b9b-4e1821ffbc37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">prices.amountmax</th>\n",
              "      <th colspan=\"3\" halign=\"left\">prices.amountmin</th>\n",
              "      <th colspan=\"3\" halign=\"left\">prices.issale</th>\n",
              "      <th colspan=\"3\" halign=\"left\">prices.amountavg</th>\n",
              "      <th colspan=\"3\" halign=\"left\">price.stat</th>\n",
              "      <th colspan=\"3\" halign=\"left\">brand.count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>median</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brand</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2 lips too</th>\n",
              "      <td>64.95</td>\n",
              "      <td>64.95</td>\n",
              "      <td>79.99</td>\n",
              "      <td>39.99</td>\n",
              "      <td>49.99</td>\n",
              "      <td>79.99</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>52.470</td>\n",
              "      <td>57.470</td>\n",
              "      <td>79.99</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adidas</th>\n",
              "      <td>109.95</td>\n",
              "      <td>129.95</td>\n",
              "      <td>159.95</td>\n",
              "      <td>76.96</td>\n",
              "      <td>84.47</td>\n",
              "      <td>159.95</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>93.455</td>\n",
              "      <td>110.455</td>\n",
              "      <td>159.95</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adidas Outdoor</th>\n",
              "      <td>99.95</td>\n",
              "      <td>99.95</td>\n",
              "      <td>119.95</td>\n",
              "      <td>99.95</td>\n",
              "      <td>99.95</td>\n",
              "      <td>119.95</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>99.950</td>\n",
              "      <td>99.950</td>\n",
              "      <td>119.95</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Altra</th>\n",
              "      <td>99.95</td>\n",
              "      <td>129.95</td>\n",
              "      <td>149.95</td>\n",
              "      <td>76.96</td>\n",
              "      <td>112.46</td>\n",
              "      <td>149.95</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>93.455</td>\n",
              "      <td>129.950</td>\n",
              "      <td>149.95</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arc'teryx</th>\n",
              "      <td>170.00</td>\n",
              "      <td>170.00</td>\n",
              "      <td>170.00</td>\n",
              "      <td>110.50</td>\n",
              "      <td>110.50</td>\n",
              "      <td>170.00</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>140.250</td>\n",
              "      <td>140.250</td>\n",
              "      <td>170.00</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6dafe8-0d64-4530-8b9b-4e1821ffbc37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf6dafe8-0d64-4530-8b9b-4e1821ffbc37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf6dafe8-0d64-4530-8b9b-4e1821ffbc37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "brand_price=df.groupby('brand').aggregate(['min', np.median, max])\n",
        "brand_price.head()"
      ],
      "id": "ffef4f1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17791f47"
      },
      "source": [
        "### Adding new column price_band"
      ],
      "id": "17791f47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95082d27"
      },
      "source": [
        "Creating a new column price_band that has values 0, 1, 2\n",
        "\n",
        "If  price <= 30             value = 0\n",
        "If  30> price <= 100        value = 1\n",
        "If  price  > 100            value = 2"
      ],
      "id": "95082d27"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6296ff9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aff2091-a0c9-4578-b9c0-e63bca605814"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id             dateadded           dateupdated  \\\n",
              "0  AVpfEf_hLJeJML431ueH  2015-05-04T12:13:08Z  2018-01-29T04:38:43Z   \n",
              "1  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   \n",
              "2  AVpi74XfLJeJML43qZAc  2017-01-27T01:23:39Z  2018-01-03T05:21:54Z   \n",
              "3  AVpjXyCc1cnluZ0-V-Gj  2017-01-27T01:25:56Z  2018-01-04T11:52:35Z   \n",
              "4  AVphGKLPilAPnD_x1Nrm  2017-01-27T01:25:56Z  2018-01-18T03:55:18Z   \n",
              "5  AVpg91ziilAPnD_xziOo  2017-01-09T19:38:58Z  2018-10-23T21:26:11Z   \n",
              "6  AVpjGKXyLJeJML43r8BH  2017-01-17T19:09:21Z  2018-10-15T15:50:13Z   \n",
              "7  AVpjGKXyLJeJML43r8BH  2017-01-17T19:09:21Z  2018-10-15T15:50:13Z   \n",
              "8  AVpfLXyhilAPnD_xWmNc  2017-01-07T20:51:17Z  2018-01-03T05:22:07Z   \n",
              "9  AVpfeWdJ1cnluZ0-lXYU  2017-01-07T20:51:22Z  2018-01-30T06:18:34Z   \n",
              "\n",
              "         brand                                         categories  \\\n",
              "0  Naturalizer  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "1     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "2     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Casual Sh...   \n",
              "3     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "4     MUK LUKS  Clothing,Shoes,Women's Shoes,All Women's Shoes...   \n",
              "5    Soft Ones  Womens Shoes,Clothing,Women's Shoes,Baby & Kid...   \n",
              "6     MUK LUKS  MUK LUKS,Womens,Women's Casual Shoes,Clothing,...   \n",
              "7     MUK LUKS  MUK LUKS,Womens,Women's Casual Shoes,Clothing,...   \n",
              "8     MUK LUKS     Clothing,Shoes,Women's Shoes,All Women's Shoes   \n",
              "9     MUK LUKS  Clothing,Shoes,Women's Shoes,Women's Winter Bo...   \n",
              "\n",
              "  primarycategories                                          imageurls  \\\n",
              "0             Shoes  https://i5.walmartimages.com/asr/861ca6cf-fa55...   \n",
              "1             Shoes  https://i5.walmartimages.com/asr/421de5d5-3a74...   \n",
              "2             Shoes  https://i5.walmartimages.com/asr/421de5d5-3a74...   \n",
              "3       Shoes,Shoes  https://i5.walmartimages.com/asr/950d38a5-0113...   \n",
              "4             Shoes  https://i5.walmartimages.com/asr/5e137bc3-c900...   \n",
              "5             Shoes  https://i5.walmartimages.com/asr/7b979ba6-fa0a...   \n",
              "6             Shoes  https://i5.walmartimages.com/asr/53c04329-c04e...   \n",
              "7             Shoes  https://i5.walmartimages.com/asr/53c04329-c04e...   \n",
              "8             Shoes  https://i5.walmartimages.com/asr/33997517-2082...   \n",
              "9             Shoes  https://i5.walmartimages.com/asr/bc1be340-3afc...   \n",
              "\n",
              "                                                keys  \\\n",
              "0  naturalizer/47147sc022,017136472311,womensnatu...   \n",
              "1  mukluks/00173650206,033977045743,muklukswomens...   \n",
              "2  mukluks/00173650206,033977045743,muklukswomens...   \n",
              "3  033977045903,muklukswomensdawnsuedescuffslippe...   \n",
              "4  mukluks/00173660206,033977045958,0033977045958...   \n",
              "5  033977052222,muklukssockmonkeyslipperbrowntwee...   \n",
              "6  womensclogwithfurlining/556122745,033977172555...   \n",
              "7  womensclogwithfurlining/556122745,033977172555...   \n",
              "8  mukluks/0003397713227,reliableofmilwuakee/0003...   \n",
              "9  muklukswomensmalenaboot/554233887,033977132542...   \n",
              "\n",
              "                                                name  prices.amountmax  ...  \\\n",
              "0  Naturalizer Danya Women N/S Open Toe Synthetic...             55.99  ...   \n",
              "1                MUK LUKS Womens Jane Suede Moccasin             47.00  ...   \n",
              "2                MUK LUKS Womens Jane Suede Moccasin             35.25  ...   \n",
              "3           MUK LUKS Womens Dawn Suede Scuff Slipper             24.75  ...   \n",
              "4           MUK LUKS Womens Dawn Suede Scuff Slipper             33.00  ...   \n",
              "5   Women's MUK LUKS¬Æ Soft Ones Sock Money Slippers             14.00  ...   \n",
              "6                Women's MUK LUKS¬Æ Faux Suede Clogs             24.00  ...   \n",
              "7                Women's MUK LUKS¬Æ Faux Suede Clogs             24.00  ...   \n",
              "8                       MUK LUKS Women's Malena Boot             59.00  ...   \n",
              "9                       MUK LUKS Women's Malena Boot             59.00  ...   \n",
              "\n",
              "   prices.issale prices.size  \\\n",
              "0          False           S   \n",
              "1           True           6   \n",
              "2          False           6   \n",
              "3          False           6   \n",
              "4           True           6   \n",
              "5           True           5   \n",
              "6          False       SMALL   \n",
              "7          False      MEDIUM   \n",
              "8           True           6   \n",
              "9           True           6   \n",
              "\n",
              "                                   prices.sourceurls  \\\n",
              "0  https://www.overstock.com/Clothing-Shoes/Women...   \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...   \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...   \n",
              "5  https://www.walmart.com/ip/MUK-LUKS-Sock-Monke...   \n",
              "6  https://www.kohls.com/product/prd-1780800/wome...   \n",
              "7  https://www.kohls.com/product/prd-1780800/wome...   \n",
              "8  https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...   \n",
              "9  https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...   \n",
              "\n",
              "                                               sizes  \\\n",
              "0  6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...   \n",
              "1                                         10,7,6,9,8   \n",
              "2                                         10,7,6,9,8   \n",
              "3                                         10,7,6,9,8   \n",
              "4                                         10,7,6,9,8   \n",
              "5                                         5,6.5,9,11   \n",
              "6        S 5-6,SMALL,M 7-8,MEDIUM,LARGE,L 9-10,L 8-9   \n",
              "7        S 5-6,SMALL,M 7-8,MEDIUM,LARGE,L 9-10,L 8-9   \n",
              "8                                         10,7,6,9,8   \n",
              "9                                         10,7,6,9,8   \n",
              "\n",
              "                                          sourceurls           upc  \\\n",
              "0  https://www.walmart.com/ip/Naturalizer-Danya-W...  017136472311   \n",
              "1  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743   \n",
              "2  https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...  033977045743   \n",
              "3  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045903   \n",
              "4  https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...  033977045958   \n",
              "5  https://www.walmart.com/ip/Soft-Ones-Kid-s-Soc...  033977052222   \n",
              "6  https://www.walmart.com/ip/Women-s-Clog-with-F...  033977098275   \n",
              "7  https://www.walmart.com/ip/Women-s-Clog-with-F...  033977098275   \n",
              "8  https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...  033977132276   \n",
              "9  https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...  033977132542   \n",
              "\n",
              "  prices.amountavg price.stat brand.count price_band  \n",
              "0           55.990      False           1          1  \n",
              "1           41.125      False          18          1  \n",
              "2           35.250      False          18          1  \n",
              "3           24.750      False          18          0  \n",
              "4           31.695      False          18          1  \n",
              "5           10.950      False           1          0  \n",
              "6           18.395      False          18          0  \n",
              "7           18.395      False          18          0  \n",
              "8           49.440      False          18          1  \n",
              "9           53.495      False          18          1  \n",
              "\n",
              "[10 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb0f2761-6f02-4c89-bb2f-8c58257e5095\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateadded</th>\n",
              "      <th>dateupdated</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primarycategories</th>\n",
              "      <th>imageurls</th>\n",
              "      <th>keys</th>\n",
              "      <th>name</th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>...</th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>prices.size</th>\n",
              "      <th>prices.sourceurls</th>\n",
              "      <th>sizes</th>\n",
              "      <th>sourceurls</th>\n",
              "      <th>upc</th>\n",
              "      <th>prices.amountavg</th>\n",
              "      <th>price.stat</th>\n",
              "      <th>brand.count</th>\n",
              "      <th>price_band</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpfEf_hLJeJML431ueH</td>\n",
              "      <td>2015-05-04T12:13:08Z</td>\n",
              "      <td>2018-01-29T04:38:43Z</td>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/861ca6cf-fa55...</td>\n",
              "      <td>naturalizer/47147sc022,017136472311,womensnatu...</td>\n",
              "      <td>Naturalizer Danya Women N/S Open Toe Synthetic...</td>\n",
              "      <td>55.99</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>S</td>\n",
              "      <td>https://www.overstock.com/Clothing-Shoes/Women...</td>\n",
              "      <td>6W,9W,7.5W,12W,8.5M,9N,9M,9.5M,10.5M,10W,8.5W,...</td>\n",
              "      <td>https://www.walmart.com/ip/Naturalizer-Danya-W...</td>\n",
              "      <td>017136472311</td>\n",
              "      <td>55.990</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/421de5d5-3a74...</td>\n",
              "      <td>mukluks/00173650206,033977045743,muklukswomens...</td>\n",
              "      <td>MUK LUKS Womens Jane Suede Moccasin</td>\n",
              "      <td>47.00</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>41.125</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpi74XfLJeJML43qZAc</td>\n",
              "      <td>2017-01-27T01:23:39Z</td>\n",
              "      <td>2018-01-03T05:21:54Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Casual Sh...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/421de5d5-3a74...</td>\n",
              "      <td>mukluks/00173650206,033977045743,muklukswomens...</td>\n",
              "      <td>MUK LUKS Womens Jane Suede Moccasin</td>\n",
              "      <td>35.25</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Jan...</td>\n",
              "      <td>033977045743</td>\n",
              "      <td>35.250</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpjXyCc1cnluZ0-V-Gj</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-04T11:52:35Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes,Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/950d38a5-0113...</td>\n",
              "      <td>033977045903,muklukswomensdawnsuedescuffslippe...</td>\n",
              "      <td>MUK LUKS Womens Dawn Suede Scuff Slipper</td>\n",
              "      <td>24.75</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045903</td>\n",
              "      <td>24.750</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVphGKLPilAPnD_x1Nrm</td>\n",
              "      <td>2017-01-27T01:25:56Z</td>\n",
              "      <td>2018-01-18T03:55:18Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/5e137bc3-c900...</td>\n",
              "      <td>mukluks/00173660206,033977045958,0033977045958...</td>\n",
              "      <td>MUK LUKS Womens Dawn Suede Scuff Slipper</td>\n",
              "      <td>33.00</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Womens-Daw...</td>\n",
              "      <td>033977045958</td>\n",
              "      <td>31.695</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AVpg91ziilAPnD_xziOo</td>\n",
              "      <td>2017-01-09T19:38:58Z</td>\n",
              "      <td>2018-10-23T21:26:11Z</td>\n",
              "      <td>Soft Ones</td>\n",
              "      <td>Womens Shoes,Clothing,Women's Shoes,Baby &amp; Kid...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/7b979ba6-fa0a...</td>\n",
              "      <td>033977052222,muklukssockmonkeyslipperbrowntwee...</td>\n",
              "      <td>Women's MUK LUKS¬Æ Soft Ones Sock Money Slippers</td>\n",
              "      <td>14.00</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Sock-Monke...</td>\n",
              "      <td>5,6.5,9,11</td>\n",
              "      <td>https://www.walmart.com/ip/Soft-Ones-Kid-s-Soc...</td>\n",
              "      <td>033977052222</td>\n",
              "      <td>10.950</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AVpjGKXyLJeJML43r8BH</td>\n",
              "      <td>2017-01-17T19:09:21Z</td>\n",
              "      <td>2018-10-15T15:50:13Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>MUK LUKS,Womens,Women's Casual Shoes,Clothing,...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/53c04329-c04e...</td>\n",
              "      <td>womensclogwithfurlining/556122745,033977172555...</td>\n",
              "      <td>Women's MUK LUKS¬Æ Faux Suede Clogs</td>\n",
              "      <td>24.00</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>SMALL</td>\n",
              "      <td>https://www.kohls.com/product/prd-1780800/wome...</td>\n",
              "      <td>S 5-6,SMALL,M 7-8,MEDIUM,LARGE,L 9-10,L 8-9</td>\n",
              "      <td>https://www.walmart.com/ip/Women-s-Clog-with-F...</td>\n",
              "      <td>033977098275</td>\n",
              "      <td>18.395</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AVpjGKXyLJeJML43r8BH</td>\n",
              "      <td>2017-01-17T19:09:21Z</td>\n",
              "      <td>2018-10-15T15:50:13Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>MUK LUKS,Womens,Women's Casual Shoes,Clothing,...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/53c04329-c04e...</td>\n",
              "      <td>womensclogwithfurlining/556122745,033977172555...</td>\n",
              "      <td>Women's MUK LUKS¬Æ Faux Suede Clogs</td>\n",
              "      <td>24.00</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>https://www.kohls.com/product/prd-1780800/wome...</td>\n",
              "      <td>S 5-6,SMALL,M 7-8,MEDIUM,LARGE,L 9-10,L 8-9</td>\n",
              "      <td>https://www.walmart.com/ip/Women-s-Clog-with-F...</td>\n",
              "      <td>033977098275</td>\n",
              "      <td>18.395</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AVpfLXyhilAPnD_xWmNc</td>\n",
              "      <td>2017-01-07T20:51:17Z</td>\n",
              "      <td>2018-01-03T05:22:07Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,All Women's Shoes</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/33997517-2082...</td>\n",
              "      <td>mukluks/0003397713227,reliableofmilwuakee/0003...</td>\n",
              "      <td>MUK LUKS Women's Malena Boot</td>\n",
              "      <td>59.00</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...</td>\n",
              "      <td>033977132276</td>\n",
              "      <td>49.440</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AVpfeWdJ1cnluZ0-lXYU</td>\n",
              "      <td>2017-01-07T20:51:22Z</td>\n",
              "      <td>2018-01-30T06:18:34Z</td>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>Clothing,Shoes,Women's Shoes,Women's Winter Bo...</td>\n",
              "      <td>Shoes</td>\n",
              "      <td>https://i5.walmartimages.com/asr/bc1be340-3afc...</td>\n",
              "      <td>muklukswomensmalenaboot/554233887,033977132542...</td>\n",
              "      <td>MUK LUKS Women's Malena Boot</td>\n",
              "      <td>59.00</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...</td>\n",
              "      <td>10,7,6,9,8</td>\n",
              "      <td>https://www.walmart.com/ip/MUK-LUKS-Women-s-Ma...</td>\n",
              "      <td>033977132542</td>\n",
              "      <td>53.495</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb0f2761-6f02-4c89-bb2f-8c58257e5095')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb0f2761-6f02-4c89-bb2f-8c58257e5095 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb0f2761-6f02-4c89-bb2f-8c58257e5095');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# creating price band to group the prices in data. price>=30 = 0,price>30 & <=100 =1, price>100 =2\n",
        "df['price_band']=0\n",
        "df.loc[df['prices.amountmax']<=30,'price_band']=0\n",
        "df.loc[(df['prices.amountmax']>30)&(df['prices.amountmax']<=100),'price_band']=1\n",
        "df.loc[df['prices.amountmax']>100,'price_band']=2\n",
        "df.head(10)"
      ],
      "id": "6296ff9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f526e07f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607b409a-53b0-4ed8-9089-8db9fb5cc884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    9421\n",
              "2     374\n",
              "0     205\n",
              "Name: price_band, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# checking the value counts in price_band\n",
        "df['price_band'].value_counts()"
      ],
      "id": "f526e07f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b0e76ba"
      },
      "source": [
        "## Label Encoding"
      ],
      "id": "2b0e76ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a7cb984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f313a1f9-3c9d-40b5-cf32-3139c0895f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 25 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 10000 non-null  object \n",
            " 1   dateadded          10000 non-null  object \n",
            " 2   dateupdated        10000 non-null  object \n",
            " 3   brand              10000 non-null  object \n",
            " 4   categories         10000 non-null  object \n",
            " 5   primarycategories  10000 non-null  object \n",
            " 6   imageurls          10000 non-null  object \n",
            " 7   keys               10000 non-null  object \n",
            " 8   name               10000 non-null  object \n",
            " 9   prices.amountmax   10000 non-null  float64\n",
            " 10  prices.amountmin   10000 non-null  float64\n",
            " 11  prices.color       10000 non-null  object \n",
            " 12  prices.currency    10000 non-null  object \n",
            " 13  prices.dateadded   10000 non-null  object \n",
            " 14  prices.dateseen    10000 non-null  object \n",
            " 15  prices.issale      10000 non-null  bool   \n",
            " 16  prices.size        10000 non-null  object \n",
            " 17  prices.sourceurls  10000 non-null  object \n",
            " 18  sizes              10000 non-null  object \n",
            " 19  sourceurls         10000 non-null  object \n",
            " 20  upc                10000 non-null  object \n",
            " 21  prices.amountavg   10000 non-null  float64\n",
            " 22  price.stat         10000 non-null  bool   \n",
            " 23  brand.count        10000 non-null  int64  \n",
            " 24  price_band         10000 non-null  int64  \n",
            "dtypes: bool(2), float64(3), int64(2), object(18)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "# Label encoding- first step checking datatypes \n",
        "df.info()"
      ],
      "id": "6a7cb984"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1efad11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba2790e-5b7b-440b-c62f-0d817e987c80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                    object\n",
              "dateadded             object\n",
              "dateupdated           object\n",
              "brand                 object\n",
              "categories            object\n",
              "primarycategories     object\n",
              "imageurls             object\n",
              "keys                  object\n",
              "name                  object\n",
              "prices.amountmax     float64\n",
              "prices.amountmin     float64\n",
              "prices.color          object\n",
              "prices.currency       object\n",
              "prices.dateadded      object\n",
              "prices.dateseen       object\n",
              "prices.issale          int64\n",
              "prices.size           object\n",
              "prices.sourceurls     object\n",
              "sizes                 object\n",
              "sourceurls            object\n",
              "upc                   object\n",
              "prices.amountavg     float64\n",
              "price.stat             int64\n",
              "brand.count            int64\n",
              "price_band             int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Converting the boolean values to 0,1 using .astype()\n",
        "df[['prices.issale','price.stat']] = df[['prices.issale','price.stat']].astype('int')\n",
        "df.dtypes"
      ],
      "id": "1efad11c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "675060cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3be9aac9-2333-4bc9-9102-08a80828136c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   prices.issale  price.stat\n",
              "0              0           0\n",
              "1              1           0\n",
              "2              0           0\n",
              "3              0           0\n",
              "4              1           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb1621ba-ee6a-42e9-ac06-ee85e77db237\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>price.stat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb1621ba-ee6a-42e9-ac06-ee85e77db237')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb1621ba-ee6a-42e9-ac06-ee85e77db237 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb1621ba-ee6a-42e9-ac06-ee85e77db237');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df[['prices.issale','price.stat']].head()"
      ],
      "id": "675060cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc3b88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f2aa0dff-63bd-42bd-e317-7f020ce6e329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         brand  brand_code\n",
              "0  Naturalizer          44\n",
              "1     MUK LUKS          39\n",
              "2     MUK LUKS          39\n",
              "3     MUK LUKS          39\n",
              "4     MUK LUKS          39\n",
              "5    Soft Ones          62\n",
              "6     MUK LUKS          39\n",
              "7     MUK LUKS          39\n",
              "8     MUK LUKS          39\n",
              "9     MUK LUKS          39"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abdcc312-d8a6-48e6-9ba6-20e878d8abac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>brand_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Soft Ones</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abdcc312-d8a6-48e6-9ba6-20e878d8abac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abdcc312-d8a6-48e6-9ba6-20e878d8abac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abdcc312-d8a6-48e6-9ba6-20e878d8abac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Encoding the brand values which are strings to integers in a new column brand_code\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb_brand = LabelEncoder()\n",
        "df['brand_code'] = lb_brand.fit_transform(df['brand'])\n",
        "df[['brand', 'brand_code']].head(10)"
      ],
      "id": "7cc3b88b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1a31ba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d81e5e-1d84-4caa-a7cc-3fd2cea47b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df['brand_code'].dtypes"
      ],
      "id": "f1a31ba2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2fdb004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d2525f-fa4e-4215-b930-d743422e3c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'dateadded', 'dateupdated', 'brand', 'categories',\n",
              "       'primarycategories', 'imageurls', 'keys', 'name', 'prices.amountmax',\n",
              "       'prices.amountmin', 'prices.color', 'prices.currency',\n",
              "       'prices.dateadded', 'prices.dateseen', 'prices.issale', 'prices.size',\n",
              "       'prices.sourceurls', 'sizes', 'sourceurls', 'upc', 'prices.amountavg',\n",
              "       'price.stat', 'brand.count', 'price_band', 'brand_code'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df.columns"
      ],
      "id": "f2fdb004"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfda1971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f86771-73a6-4c44-9535-30bcc6e52c66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "653"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df['id'].nunique()"
      ],
      "id": "dfda1971"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "154d1eb3"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "154d1eb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5f47b16"
      },
      "source": [
        "## Outliers"
      ],
      "id": "e5f47b16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbc4a9b8"
      },
      "outputs": [],
      "source": [
        "outliers = df[df['prices.amountmax'] > df['prices.amountmax'].mean() + 2 * df['prices.amountmax'].std()]"
      ],
      "id": "dbc4a9b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c31162a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "cb05a2df-1192-4c7c-d047-e640e354d7a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       prices.amountmax  prices.amountmin  prices.issale  prices.amountavg  \\\n",
              "count        373.000000        373.000000     373.000000        373.000000   \n",
              "mean         133.312601        108.058338       0.284182        120.685469   \n",
              "std           31.507292         40.969440       0.451630         33.267914   \n",
              "min          109.000000         37.490000       0.000000         78.745000   \n",
              "25%          119.000000         79.970000       0.000000        101.990000   \n",
              "50%          120.000000        110.000000       0.000000        119.000000   \n",
              "75%          140.000000        129.950000       1.000000        129.950000   \n",
              "max          359.950000        359.950000       1.000000        359.950000   \n",
              "\n",
              "       price.stat  brand.count  price_band  brand_code  \n",
              "count       373.0   373.000000       373.0  373.000000  \n",
              "mean          1.0   124.147453         2.0   56.399464  \n",
              "std           0.0   201.736899         0.0   40.512360  \n",
              "min           1.0     1.000000         2.0    1.000000  \n",
              "25%           1.0     8.000000         2.0   25.000000  \n",
              "50%           1.0    21.000000         2.0   55.000000  \n",
              "75%           1.0   111.000000         2.0   81.000000  \n",
              "max           1.0   670.000000         2.0  124.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2ff93df-25fa-47b8-8d99-83f47e9baa01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>prices.amountmin</th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>prices.amountavg</th>\n",
              "      <th>price.stat</th>\n",
              "      <th>brand.count</th>\n",
              "      <th>price_band</th>\n",
              "      <th>brand_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>373.000000</td>\n",
              "      <td>373.000000</td>\n",
              "      <td>373.000000</td>\n",
              "      <td>373.000000</td>\n",
              "      <td>373.0</td>\n",
              "      <td>373.000000</td>\n",
              "      <td>373.0</td>\n",
              "      <td>373.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>133.312601</td>\n",
              "      <td>108.058338</td>\n",
              "      <td>0.284182</td>\n",
              "      <td>120.685469</td>\n",
              "      <td>1.0</td>\n",
              "      <td>124.147453</td>\n",
              "      <td>2.0</td>\n",
              "      <td>56.399464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>31.507292</td>\n",
              "      <td>40.969440</td>\n",
              "      <td>0.451630</td>\n",
              "      <td>33.267914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>201.736899</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.512360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>109.000000</td>\n",
              "      <td>37.490000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.745000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>119.000000</td>\n",
              "      <td>79.970000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.990000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>120.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>140.000000</td>\n",
              "      <td>129.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>129.950000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>359.950000</td>\n",
              "      <td>359.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>359.950000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>670.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>124.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2ff93df-25fa-47b8-8d99-83f47e9baa01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2ff93df-25fa-47b8-8d99-83f47e9baa01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2ff93df-25fa-47b8-8d99-83f47e9baa01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "outliers.describe()"
      ],
      "id": "3c31162a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf37d00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "17ff3943-3c7d-4eec-94f2-f568ed0e3c57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d7cf590>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "outliers.boxplot()"
      ],
      "id": "cf37d00c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ccb59f8"
      },
      "source": [
        "### prices.amountmax column"
      ],
      "id": "5ccb59f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8c0d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "d624374f-ee3d-4568-fab3-f816c9676148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d672110>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.boxplot(y='prices.amountmax',data = df)"
      ],
      "id": "f8c0d7cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2be3f3c6"
      },
      "source": [
        "### prices.amountmin column"
      ],
      "id": "2be3f3c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fc69660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "ee767051-fb63-4cb9-f012-27f9cabf2af9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d197050>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAADrCAYAAACGqorWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVQ0lEQVR4nO3df7BfdX3n8eebhEKslECIaTYJBpu4DnUwliti7WwxFRvZuhHdYcXZEpUhdYsCo9sVcTvSP3DdbSuTZLt0I1CTjihYpESb3Up+4XasP24wDSB2eqthQjYk1wuEKF3oDe/945x7+Cbc3Hu+yT33fG/yfMyc+X7P55zz/b6vI3l9P+d8zudEZiJJEsApbRcgSeodhoIkqWIoSJIqhoIkqWIoSJIqhoIkqTK97QKOxznnnJMLFy5suwxJmlK2b9/+k8ycPdq2KR0KCxcupL+/v+0yJGlKiYjHj7bN00eSpIqhIEmqGAqSpIqhIEmqGApSA7Zs2cIll1zC1q1b2y5F6oqhIDXgM5/5DAC33HJLy5VI3TEUpAm2ZcsWhoeHARgeHra3oCnFUJAm2EgvYYS9BU0lhoI0wUZ6CUdbl3qZoSBNsOnTp4+5LvWyxkIhIk6PiO9GxN9FxKMR8Qdl+xci4scRsaNclpTtERGrI2IgInZGxK80VZvUpJtuuumw9U996lMtVSJ1r8mewvPA0sx8A7AEWBYRF5fbfi8zl5TLjrLtncDiclkJ3NZgbVJjli5dWvUOpk+fztve9raWK5LqaywUsvDTcvXUcskxDlkOrC+P+zYwMyLmNlWf1KSR3oK9BE01jV5TiIhpEbED2A88kJnfKTfdUp4iujUiTivb5gG7Ow5/omw78jNXRkR/RPQPDg42Wb50zJYuXcq2bdvsJWjKaTQUMvNQZi4B5gMXRcTrgU8CrwPeBJwNfKLLz1ybmX2Z2Td79qjTgUuSjtGkjD7KzGeArcCyzNxbniJ6Hvgz4KJytz3Ago7D5pdtkqRJ0uToo9kRMbN8PwO4FPjhyHWCiAjg3cAj5SEbgKvKUUgXAwcyc29T9UmSXq7JAdRzgXURMY0ifO7JzK9HxJaImA0EsAP4cLn/RuAyYAB4Dvhgg7VJkkbRWChk5k7gjaO0Lz3K/glc21Q9kqTxeUezJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKo2FQkScHhHfjYi/i4hHI+IPyvbzIuI7ETEQEXdHxM+V7aeV6wPl9oVN1SZJGl2TPYXngaWZ+QZgCbAsIi4G/itwa2YuAp4Gri73vxp4umy/tdxPkjSJGguFLPy0XD21XBJYCvxF2b4OeHf5fnm5Trn9NyIimqpPkvRyjV5TiIhpEbED2A88APwj8ExmDpe7PAHMK9/PA3YDlNsPALOarE+SdLhGQyEzD2XmEmA+cBHwuuP9zIhYGRH9EdE/ODh43DVKkl4yKaOPMvMZYCvwFmBmREwvN80H9pTv9wALAMrtZwJDo3zW2szsy8y+2bNnN167JJ1Mmhx9NDsiZpbvZwCXAo9RhMO/LXdbAdxfvt9QrlNu35KZ2VR9UpOGhoa47rrrGBp62e8aqac12VOYC2yNiJ3A94AHMvPrwCeAj0XEAMU1gzvK/e8AZpXtHwNubLA2qVHr1q3j4YcfZv369W2XInUlpvKP8b6+vuzv72+7DOkwQ0NDXHnllbzwwgucdtpp3HXXXcya5ZgJ9Y6I2J6ZfaNt845maYKtW7eOF198EYBDhw7ZW9CUYihIE2zTpk0MDxejroeHh3nggQdarkiqz1CQJtjb3/52pk8vBthNnz6dSy+9tOWKpPoMBWmCrVixglNOKf7TmjZtGldddVXLFUn1GQrSBJs1axbLli0jIli2bJkXmTWlTB9/F0ndWrFiBbt27bKXoCnHUJAaMGvWLFavXt12GVLXPH0kSaoYCpKkiqEgSaoYCpKkiqEgSaoYCpKkiqEgSaoYCpKkiqEgSaoYCpKkiqEgSarUmvsoIl4L/B7w6s5jMnNpQ3VJklpQd0K8rwB/CnweOFTngIhYAKwH5gAJrM3MVRFxM3ANMFjuelNmbiyP+SRwdfkd12XmX9esT5I0AeqGwnBm3tblZw8DH8/MhyLiDGB7RIw8l/DWzPyjzp0j4nzgfcAvA/8C2BQRr83MWiEkSTp+da8pfC0ifjci5kbE2SPLWAdk5t7MfKh8fxB4DJg3xiHLgS9n5vOZ+WNgALioZn2SpAlQNxRWUFxT+BawvVz6635JRCwE3gh8p2z6SETsjIg7I+Kssm0esLvjsCcYO0QkSROsVihk5nmjLK+pc2xEvBK4F7ghM58FbgN+CVgC7AX+uJuCI2JlRPRHRP/g4OD4B0iSahvzmkJELM3MLRHxntG2Z+ZXxzn+VIpA+OLIvpm5r2P754Gvl6t7gAUdh88v2478zrXAWoC+vr4c6/slSd0Z70LzrwNbgHeNsi2Bo4ZCRARwB/BYZn6uo31uZu4tVy8HHinfbwDuiojPUVxoXgx8t84fIUmaGGOGQmZ+unz94DF89luB3wYejogdZdtNwJURsYQiVHYBv1N+x6MRcQ/wA4qRS9c68kiSJlfdm9dmAlcBCzn85rXrjnZMZv4NEKNs2jjGMbcAt9SpSZI08erep7AR+DbwMPBic+VIktpUNxROz8yPNVqJJKl1de9T+POIuKabm9ckSVNP3Z7CC8AfAp+iuEBM+VrrXgVJ0tRQNxQ+DizKzJ80WYwkqV11Tx8NAM81WYgkqX11ewo/A3ZExFbg+ZHGsYakSpKmnrqh8Jfl0skpJiTpBFM3FGZm5qrOhoi4voF6JEkt6mbq7CN9YALrkCT1gPFmSb0SeD9wXkRs6Nh0BvBUk4VJkibfeKePvkXxzINzOPy5BweBnU0VJUlqx3izpD4OPA68ZXLKkSS1qdY1hYh4T0T8Q0QciIhnI+JgRDzbdHGSpMlVd/TRfwPelZmPNVmMJKlddUcf7TMQJOnEV7en0B8Rd1PcwNZ5R/OYz2iWJE0tdUPhFyjmPnpHR9uYz2iWJE09tULhGJ/RLEmaYuo+o/nPGGWuo8z80BjHLADWA3PKY9dm5qry4Tx3UzzveRdwRWY+HREBrAIuo+iVfCAzH+rqr5EkHZe6F5q/DvxVuWymOJ3003GOGQY+npnnAxcD10bE+cCNwObMXFx+1o3l/u8EFpfLSuC2Lv4OSdIEqHv66N7O9Yj4EvA34xyzl+JuaDLzYEQ8BswDlgOXlLutA7YBnyjb12dmAt+OiJkRMbf8HEnSJKjbUzjSYuBVdXeOiIXAG4HvAHM6/qF/kuL0EhSBsbvjsCfKNknSJKl7TeEgxXWBKF+fpPh1X+fYVwL3Ajdk5rPFpYNCZmZEdPVchohYSXF6iXPPPbebQyVJ46h7+uiMY/nwiDiVIhC+2HFPw76R00IRMRfYX7bvARZ0HD6/bDuylrXAWoC+vj4f9CNJE6j26aOI+DcR8Ufl8ls19g/gDuCxzPxcx6YNvPR8hhXA/R3tV0XhYuCA1xMkaXLVPX30WeBNwBfLpusj4lcz86YxDnsr8NvAwxGxo2y7CfgscE9EXE0xA+sV5baNFMNRByiGpHpvhCRNsigG+4yzU8ROYElmvliuTwO+n5kXNFzfmPr6+rK/v7/NEiRpyomI7ZnZN9q2bkYfzex4f+bxlSRJ6kV15z76L8D3I2IrxQikf8VLN51Jkk4QtXoKmfkliruSv0oxmugtmXl3k4VJU9nQ0BDXXXcdQ0NDbZcidaWb00ezy9fpwK9GxHsaqEc6IaxevZqdO3eyZs2atkuRulJ39NGdwAXAo8CLZbNTZ0ujGBoa4sEHHwRg27ZtDA0NMWvWrJarkuqpe03h4nJiO0njWL169WHra9as4eabb26nGKlLdU8f/W05w6mkcYz0EkZs27atnUKkY1C3p7CeIhiepHgcZ1BMXdTqfQqSpIlVNxTuoLw7mZeuKUgaxYIFC9i9e/dh69JUUff00WBmbsjMH2fm4yNLo5VJU9T1119/2PoNN9zQUiVS9+r2FL4fEXcBX6M4fQRAx8ynkkrf+MY3XrZ+4YUXtlSN1J26PYUZFGHwDuBd5TLuTKnSyWjz5s2HrW/atKmlSqTu1X2egjOWSjUdOnRozHWpl9W9ee104Grgl4HTR9oz80MN1SVNWRFB5+zDnU8blHpd3dNHfw78IvCbwIMUT0U72FRR0lR25HT0daanl3pF3VBYlJm/D/wsM9cB/xp4c3NlSZLaUDcU/rl8fSYiXk/xPIVXNVOSJKktdYekro2Is4D/TPEs5VcCv99YVZKkVtQdfXR7+fabwGuaK0eS1KZunqdwmIj4lXG23xkR+yPikY62myNiT0TsKJfLOrZ9MiIGIuLvI+I3j7UuSdKxO+ZQAP7DONu/ACwbpf3WzFxSLhsByhlY30cx5HUZ8D8iYtpx1Ca15pprrjls/cMf/nBLlUjdO+ZQyMxrxtn+TeCpmh+3HPhyZj6fmT8GBoCLjrU2qU3333//Yev33XdfS5VI3asVChHx1oj4+fL9v4+Iz0XEq4/xOz8SETvL00tnlW3zgN0d+zxRtklTzv79+w9b37dvX0uVSN2r21O4DXguIt4AfBz4R4pnLHTrNuCXgCXAXuCPu/2AiFgZEf0R0T84OHgMJUiSjqZuKAxncVvmcuC/Z+afAGd0+2WZuS8zD2Xmi8DneekU0R6gc9L5+WXbaJ+xNjP7MrNv9uzZ3ZYgSRpD3VA4GBGfpHjQzl9FxCnAqd1+WUTM7Vi9HBgZmbQBeF9EnBYR5wGLge92+/mSpONT9+a1fwe8H/hQZj4ZEecCfzjWARHxJeAS4JyIeAL4NHBJRCwBEtgF/A5AZj4aEfcAPwCGgWsz06klNSWdeeaZHDhwoFqfOXNmi9VI3al789qTEXEvxS94gJ8AYw6pyMwrR2m+Y4z9bwFuqVOP1Ms6AwHgmWeeaakSqXt1Rx9dA/wF8D/LpnnAXzZVlCSpHXWvKVwLvBV4FiAz/wEnxJOkE07dUHg+M18YWYmI6RTXBSQd4chrCGedddZR9pR6T91QeDAibgJmRMSlwFeArzVXljR13XHH4ZfObr/99qPsKfWeuqFwIzAIPEwxYmgjxTTako7w3ve+d8x1qZfVHZI6A7gzMz8PUE5WNwN4rqnCJEmTr25PYTNFCIyYAWya+HIkSW2qGwqnZ+ZPR1bK969opiRJUlvqhsLPOh+qExEXAv/UTEmSpLbUvaZwA/CViPi/QAC/SDH1hSTpBFJ3movvRcTrgH9ZNv19Zv5zc2VJktowZihExNLM3BIR7zli02sjgsz8aoO1SZIm2Xg9hV8HtgDvGmVbAoaCJJ1AxgyFzPx0+eyE/5WZ90xSTZKklow7+qh8Stp/moRaJEktqzskdVNE/MeIWBARZ48sjVYmSZp03Tx5LYHfPaL9NRNbjiSpTXVD4XyKQPg1inD4P8CfNlWUJKkddUNhHcUDdlaX6+8v265ooihJUjvqhsLrM/P8jvWtEfGDsQ6IiDuB3wL2Z+bry7azgbuBhcAu4IrMfDoiAlgFXEYx8+oHMvOhbv4QSdLxq3uh+aGIuHhkJSLeDPSPc8wXgGVHtN0IbM7MxRQzr95Ytr8TWFwuK4HbatYlSZpAdUPhQuBbEbErInYBfwu8KSIejoidox2Qmd8EnjqieTnFaSfK13d3tK/PwreBmRExt4u/Q5I0AeqePjryF/+xmpOZe8v3TwJzyvfzgN0d+z1Rtu3lCBGxkqI3wbnnnjtBZUmSoP6EeI9P9BdnZkZEHsNxa4G1AH19fV0fL0k6urqnjybKvpHTQuXr/rJ9D7CgY7/5ZZskaRLVPX00UTYAK4DPlq/3d7R/JCK+DLwZONBxmklTxJo1axgYGGi7jJ50/fXXt11CqxYtWsRHP/rRtstQDY2FQkR8CbgEOCcingA+TREG90TE1cDjvHSfw0aK4agDFENSP9hUXZKko4vMqXtavq+vL/v7xxsZK02uyy+/nKeffrpanzVrFvfee2+LFUmHi4jtmdk32rbJvqYgnfDuu+++w9YNBE0lhoLUgOIm/aKXIE0lk32hWTopXHDBBQCsWrWq5Uqk7thTkCRVDAVJUsVQkCRVDAVJUsVQkCRVDAVJUsVQkCRVDAVJUsVQkCRVDAVJUsVQkCRVDAVJUsVQkCRVnCX1OPkISo1m5P8TJ/tjOPVyvf5oUkPhOA0MDLDjkcc49Iqz2y5FPeSUF4onGm7/0b6WK1EvmfbcU22XMC5DYQIcesXZ/NPrLmu7DEk9bsYPN7ZdwrhaCYWI2AUcBA4Bw5nZFxFnA3cDC4FdwBWZ+fTRPkOSNPHavND8tsxc0vHw6BuBzZm5GNhcrkuSJlEvnT5aDlxSvl8HbAM+0VYxde3Zs4dpzx2YEt1CSe2a9twQe/YMt13GmNrqKSTwjYjYHhEry7Y5mbm3fP8kMGe0AyNiZUT0R0T/4ODgZNQqSSeNtnoKv5aZeyLiVcADEfHDzo2ZmRGRox2YmWuBtQB9fX2j7jOZ5s2bx5PPT/dCs6RxzfjhRubNG/X3bs9opaeQmXvK1/3AfcBFwL6ImAtQvu5vozZJOplNeihExM9HxBkj74F3AI8AG4AV5W4rgPsnuzZJOtm1cfpoDnBfRIx8/12Z+b8j4nvAPRFxNfA4cEULtUnSSW3SQyEzfwS8YZT2IeA3JrseSdJLemlI6pQ17bmnHJKqw5zy/54F4MXTf6HlStRLimkuevtCs6FwnBYtWtR2CepBAwMHAVj0mt7+B0CTbU7P/5thKBynXp7tUO0ZmR111apVLVcidcfnKUiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKliKEiSKj33PIWIWAasAqYBt2fmZ1suSTWtWbOGgYGBtsvoCSP/O4w8V+Fkt2jRIp89MkX0VE8hIqYBfwK8EzgfuDIizm+3Kql7M2bMYMaMGW2XIXWt13oKFwEDmfkjgIj4MrAc+EGrVakWfwlKU19P9RSAecDujvUnyjZJ0iTotVAYV0SsjIj+iOgfHBxsuxxJOqH0WijsARZ0rM8v2yqZuTYz+zKzb/bs2ZNanCSd6HotFL4HLI6I8yLi54D3ARtarkmSTho9daE5M4cj4iPAX1MMSb0zMx9tuSxJOmn0VCgAZOZGYGPbdUjSyajXTh9JklpkKEiSKpGZbddwzCJiEHi87TqkozgH+EnbRUijeHVmjjp8c0qHgtTLIqI/M/varkPqhqePJEkVQ0GSVDEUpOasbbsAqVteU5AkVewpSJIqhoIkqWIoSJIqhoIkqWIoSJIq/x/5ZfUiLVgeGQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.boxplot(y='prices.amountmin',data = df)"
      ],
      "id": "9fc69660"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03df34dd"
      },
      "source": [
        "### prices.amountavg column"
      ],
      "id": "03df34dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e9b1d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "0c266f80-450a-404e-e46d-e6478f2a9c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d11d950>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.boxplot(y='prices.amountavg',data = df)"
      ],
      "id": "9e9b1d92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2d12a2"
      },
      "source": [
        "### brand.count column"
      ],
      "id": "8a2d12a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4194f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "f4ec6783-26ab-4882-cdaf-8a7cdc9e72de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d08f9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.boxplot(y='brand.count',data = df)"
      ],
      "id": "c4194f36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087bbe1f"
      },
      "source": [
        "### brand_code column"
      ],
      "id": "087bbe1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd437dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "54a8a0a1-47cc-4353-fad5-265c3b1d3114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faa8d074c90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.boxplot(y='brand_code',data = df)"
      ],
      "id": "cd437dfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d7a7cc6"
      },
      "outputs": [],
      "source": [
        "# 109.98999999999998\n",
        "# 29.990000000000013"
      ],
      "id": "2d7a7cc6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0285cd00"
      },
      "outputs": [],
      "source": [
        "num_values = ['prices.amountmax','prices.amountmin','prices.amountavg']"
      ],
      "id": "0285cd00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3998620"
      },
      "outputs": [],
      "source": [
        "upp_and_low_limits = {}\n",
        "for item in num_values:\n",
        "    Q1 = np.percentile(df[item],25,interpolation='midpoint')\n",
        "    Q3 = np.percentile(df[item],75,interpolation='midpoint')\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    up_lim = Q3 + 1.5 * IQR\n",
        "    low_lim = Q1 - 1.5 * IQR\n",
        "#     print(up_lim)\n",
        "#     print(low_lim)\n",
        "    upp_and_low_limits[item+'_up'] = up_lim\n",
        "    upp_and_low_limits[item+'_low'] = low_lim\n",
        "    df[item] = np.where(df[item] > up_lim, df[item].median(), df[item])\n",
        "    df[item] = np.where(df[item] < low_lim,df[item].median(), df[item])\n",
        "    \n",
        "#     print()\n",
        "#     print()\n",
        "    "
      ],
      "id": "f3998620"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "805beae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f673692-e9e7-4688-ad6e-548eee0dd5e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prices.amountavg_low': 23.740000000000013,\n",
              " 'prices.amountavg_up': 93.73999999999998,\n",
              " 'prices.amountmax_low': 29.990000000000013,\n",
              " 'prices.amountmax_up': 109.98999999999998,\n",
              " 'prices.amountmin_low': 3.740000000000002,\n",
              " 'prices.amountmin_up': 93.74000000000001}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "upp_and_low_limits"
      ],
      "id": "805beae3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99325d49"
      },
      "source": [
        "## Creating a dataframe with numerical values for the ML model"
      ],
      "id": "99325d49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7396eb7"
      },
      "outputs": [],
      "source": [
        "data =df[['brand','prices.amountmax','prices.issale','price.stat','brand.count','price_band','brand_code']]"
      ],
      "id": "a7396eb7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac62e87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1f4dde57-9024-4d85-9c11-6d71eca61ad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         brand  prices.amountmax  prices.issale  price.stat  brand.count  \\\n",
              "0  Naturalizer             55.99              0           0            1   \n",
              "1     MUK LUKS             47.00              1           0           18   \n",
              "2     MUK LUKS             35.25              0           0           18   \n",
              "3     MUK LUKS             64.99              0           0           18   \n",
              "4     MUK LUKS             33.00              1           0           18   \n",
              "\n",
              "   price_band  brand_code  \n",
              "0           1          44  \n",
              "1           1          39  \n",
              "2           1          39  \n",
              "3           0          39  \n",
              "4           1          39  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be9771e2-812f-4361-bb3f-44366d950b9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>price.stat</th>\n",
              "      <th>brand.count</th>\n",
              "      <th>price_band</th>\n",
              "      <th>brand_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>55.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>47.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>35.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be9771e2-812f-4361-bb3f-44366d950b9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be9771e2-812f-4361-bb3f-44366d950b9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be9771e2-812f-4361-bb3f-44366d950b9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data.head()"
      ],
      "id": "ac62e87f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59e113b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbf4b6c-c20d-4c9c-e0b4-f530ad177476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   brand             10000 non-null  object \n",
            " 1   prices.amountmax  10000 non-null  float64\n",
            " 2   prices.issale     10000 non-null  int64  \n",
            " 3   price.stat        10000 non-null  int64  \n",
            " 4   brand.count       10000 non-null  int64  \n",
            " 5   price_band        10000 non-null  int64  \n",
            " 6   brand_code        10000 non-null  int64  \n",
            "dtypes: float64(1), int64(5), object(1)\n",
            "memory usage: 547.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ],
      "id": "59e113b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09782846"
      },
      "outputs": [],
      "source": [
        "# New df to split data contains only numerical values.\n",
        "newdf = data[['brand','prices.amountmax','prices.issale','price.stat','brand.count','price_band','brand_code']]"
      ],
      "id": "09782846"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed0c57db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be90d1b2-425c-4203-ba9e-bd923ef7750a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 5)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(newdf.iloc[:,1:6])\n",
        "y = np.array(newdf['brand_code'])\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "id": "ed0c57db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de63bb03"
      },
      "outputs": [],
      "source": [
        "#Creating training and test splits(The code splits the dataset into 70% train data and 30% test data)\n",
        "from sklearn.model_selection import train_test_split  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "id": "de63bb03"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98aae9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2b7f59ec-6dad-4daa-c722-a21ccd2dfea9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            brand  prices.amountmax  prices.issale  price.stat  brand.count  \\\n",
              "0     Naturalizer             55.99              0           0            1   \n",
              "1        MUK LUKS             47.00              1           0           18   \n",
              "2        MUK LUKS             35.25              0           0           18   \n",
              "3        MUK LUKS             64.99              0           0           18   \n",
              "4        MUK LUKS             33.00              1           0           18   \n",
              "...           ...               ...            ...         ...          ...   \n",
              "9995        Asics             64.99              1           1           19   \n",
              "9996        Asics             64.99              1           1           19   \n",
              "9997       Kaanas             64.99              1           1            1   \n",
              "9998         Nike             64.99              1           1          179   \n",
              "9999     OTZShoes             99.95              1           0            1   \n",
              "\n",
              "      price_band  brand_code  \n",
              "0              1          44  \n",
              "1              1          39  \n",
              "2              1          39  \n",
              "3              0          39  \n",
              "4              1          39  \n",
              "...          ...         ...  \n",
              "9995           2           5  \n",
              "9996           2           5  \n",
              "9997           2          31  \n",
              "9998           2          46  \n",
              "9999           1          47  \n",
              "\n",
              "[10000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3030ad3d-7843-49d1-8f97-c36e27f319b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>prices.amountmax</th>\n",
              "      <th>prices.issale</th>\n",
              "      <th>price.stat</th>\n",
              "      <th>brand.count</th>\n",
              "      <th>price_band</th>\n",
              "      <th>brand_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naturalizer</td>\n",
              "      <td>55.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>47.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>35.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MUK LUKS</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Asics</td>\n",
              "      <td>64.99</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Asics</td>\n",
              "      <td>64.99</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Kaanas</td>\n",
              "      <td>64.99</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Nike</td>\n",
              "      <td>64.99</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>179</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>OTZShoes</td>\n",
              "      <td>99.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3030ad3d-7843-49d1-8f97-c36e27f319b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3030ad3d-7843-49d1-8f97-c36e27f319b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3030ad3d-7843-49d1-8f97-c36e27f319b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "newdf"
      ],
      "id": "98aae9f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ae5139"
      },
      "source": [
        "### Scaling"
      ],
      "id": "a4ae5139"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "624548bf"
      },
      "outputs": [],
      "source": [
        "#Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)  "
      ],
      "id": "624548bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQi-tww4Svw"
      },
      "source": [
        "# Model creation"
      ],
      "id": "wnQi-tww4Svw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74bc79fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caa9340-2fc6-4e4b-b0e2-d990ccee6ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logit_model=LogisticRegression()\n",
        "logit_model.fit(X_train,y_train)\n",
        "y_pred=logit_model.predict(X_test)"
      ],
      "id": "74bc79fd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce14c451"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,classification_report"
      ],
      "id": "ce14c451"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xKQsgpBQs1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc4da35-21bc-486e-ae1d-df07fa743c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report For Logistic regression:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           9       0.45      0.45      0.45        11\n",
            "          10       0.00      0.00      0.00        12\n",
            "          11       0.00      0.00      0.00         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         4\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         2\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       0.00      0.00      0.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          39       0.60      0.60      0.60         5\n",
            "          41       0.00      0.00      0.00         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       0.15      0.40      0.22        43\n",
            "          48       0.00      0.00      0.00         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         6\n",
            "          53       0.00      0.00      0.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       0.08      0.22      0.12         9\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.00      0.00      0.00         2\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         4\n",
            "          70       0.00      0.00      0.00         6\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       0.00      0.00      0.00         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       0.72      0.97      0.83       220\n",
            "          78       0.00      0.00      0.00        31\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00        54\n",
            "          81       0.00      0.00      0.00        35\n",
            "          83       0.74      0.48      0.58        54\n",
            "          84       0.00      0.00      0.00        13\n",
            "          86       0.09      0.14      0.11       105\n",
            "          87       0.00      0.00      0.00        22\n",
            "          88       0.26      0.31      0.29       108\n",
            "          89       0.09      0.33      0.14        15\n",
            "          90       0.64      1.00      0.78       170\n",
            "          91       0.00      0.00      0.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          95       0.00      0.00      0.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       0.00      0.00      0.00         2\n",
            "          98       0.00      0.00      0.00         4\n",
            "          99       0.00      0.00      0.00         6\n",
            "         100       0.00      0.00      0.00         6\n",
            "         101       0.40      0.17      0.24        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       0.32      0.88      0.47        25\n",
            "         106       0.00      0.00      0.00        39\n",
            "         107       0.00      0.00      0.00        66\n",
            "         108       0.06      0.06      0.06        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.00      0.00      0.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.00      0.00      0.00         6\n",
            "         114       0.00      0.00      0.00         1\n",
            "         115       0.00      0.00      0.00         2\n",
            "         116       0.00      0.00      0.00        36\n",
            "         117       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00        54\n",
            "         119       0.03      0.14      0.05        43\n",
            "         120       0.33      0.24      0.28       128\n",
            "         121       0.00      0.00      0.00         5\n",
            "         122       0.00      0.00      0.00        72\n",
            "         123       0.00      0.00      0.00        24\n",
            "         124       0.68      0.74      0.71       137\n",
            "         125       0.00      0.00      0.00         2\n",
            "         126       0.00      0.00      0.00         5\n",
            "         127       0.00      0.00      0.00        14\n",
            "         128       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.58      3000\n",
            "   macro avg       0.08      0.09      0.08      3000\n",
            "weighted avg       0.53      0.58      0.54      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report For Logistic regression:\",classification_report(y_test, y_pred)) "
      ],
      "id": "-xKQsgpBQs1I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "959ea1eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fe3201-eecb-4041-b046-bff8d6e503e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred))"
      ],
      "id": "959ea1eb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76e04a5a"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "acc_values=[]\n",
        "neighbors=np.arange(3,15)\n",
        "for k in neighbors:\n",
        "    classifier=KNeighborsClassifier(n_neighbors=k,metric='minkowski')\n",
        "    classifier.fit(X_train,y_train)\n",
        "    y_pred1=classifier.predict(X_test)\n",
        "    acc=accuracy_score(y_test,y_pred1)\n",
        "    acc_values.append(acc)"
      ],
      "id": "76e04a5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8af5c0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898df4af-cd5d-418d-a2f0-b2259e29a926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9786666666666667,\n",
              " 0.978,\n",
              " 0.9743333333333334,\n",
              " 0.972,\n",
              " 0.9713333333333334,\n",
              " 0.9693333333333334,\n",
              " 0.9643333333333334,\n",
              " 0.9646666666666667,\n",
              " 0.959,\n",
              " 0.9566666666666667,\n",
              " 0.9536666666666667,\n",
              " 0.9496666666666667]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "acc_values"
      ],
      "id": "8af5c0d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b53d628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2b14a597-1782-49c0-c207-7ee82eb13281"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(neighbors,acc_values,'o-')\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('accuracy')"
      ],
      "id": "1b53d628"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MupIeQ5ZoHP"
      },
      "source": [
        "we get max accuracy with k = 3"
      ],
      "id": "3MupIeQ5ZoHP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19f23065"
      },
      "outputs": [],
      "source": [
        "classifier=KNeighborsClassifier(n_neighbors=3,metric='minkowski')\n",
        "classifier.fit(X_train,y_train)\n",
        "y_pred1=classifier.predict(X_test)"
      ],
      "id": "19f23065"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxlbmPMTRB_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799b5926-b579-4ec7-a914-cf5bb9657f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for KNN:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.33      0.14      0.20         7\n",
            "           2       0.33      1.00      0.50         1\n",
            "           3       0.50      0.75      0.60         8\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.67      0.67      0.67         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.50      1.00      0.67         3\n",
            "           9       0.70      0.64      0.67        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.33      0.33      0.33         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       0.33      1.00      0.50         1\n",
            "          23       0.50      1.00      0.67         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       1.00      1.00      1.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          33       1.00      1.00      1.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       0.44      0.80      0.57         5\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       1.00      0.60      0.75         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      0.50      0.67         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       0.83      0.83      0.83         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      0.98      0.99        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      0.90      0.95        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.50      0.33      0.40         3\n",
            "          65       0.40      1.00      0.57         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       1.00      1.00      1.00         1\n",
            "          69       0.40      0.50      0.44         4\n",
            "          70       1.00      0.83      0.91         6\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       1.00      0.25      0.40         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       0.89      1.00      0.94         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         0\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       0.80      1.00      0.89         4\n",
            "          99       0.86      1.00      0.92         6\n",
            "         100       0.86      1.00      0.92         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.60      1.00      0.75         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       0.50      1.00      0.67         1\n",
            "         115       0.50      0.50      0.50         2\n",
            "         116       0.97      1.00      0.99        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       1.00      1.00      1.00         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       0.83      1.00      0.91         5\n",
            "         127       0.93      1.00      0.97        14\n",
            "         128       1.00      0.89      0.94         9\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.65      0.69      0.66      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report for KNN:\",classification_report(y_test, y_pred1)) "
      ],
      "id": "dxlbmPMTRB_e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbd90457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87bedd6-2b70-4f71-d2f4-2205f50a5609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[ 4  0  0 ...  0  0  0]\n",
            " [ 0  1  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 0  0  0 ...  0  0  8]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred1))"
      ],
      "id": "dbd90457"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlBiOsPACSrA"
      },
      "outputs": [],
      "source": [
        "#decision tree classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "data_model=DecisionTreeClassifier()\n",
        "data_model.fit(X_train,y_train)\n",
        "y_pred2=data_model.predict(X_test)"
      ],
      "id": "OlBiOsPACSrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohaqx-jyRZxE",
        "outputId": "2dbf3de8-2baa-462d-f79b-48cd9bf6be53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report For Decision Tree:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.80      0.50      0.62         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.50      1.00      0.67         3\n",
            "           9       1.00      1.00      1.00        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.25      0.67      0.36         3\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         1\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.25      1.00      0.40         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       1.00      1.00      1.00         5\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       1.00      1.00      1.00         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       1.00      1.00      1.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          48       1.00      1.00      1.00         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       1.00      1.00      1.00         2\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      1.00      1.00        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          62       0.00      0.00      0.00         0\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       0.50      1.00      0.67         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       1.00      1.00      1.00         1\n",
            "          69       1.00      0.50      0.67         4\n",
            "          70       1.00      0.83      0.91         6\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       1.00      1.00      1.00         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       0.50      1.00      0.67         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       1.00      1.00      1.00         8\n",
            "          93       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       1.00      1.00      1.00         6\n",
            "         100       1.00      1.00      1.00         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         103       0.00      0.00      0.00         0\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       1.00      1.00      1.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       1.00      1.00      1.00         1\n",
            "         115       1.00      1.00      1.00         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       1.00      1.00      1.00         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           0.99      3000\n",
            "   macro avg       0.69      0.71      0.69      3000\n",
            "weighted avg       0.98      0.99      0.98      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report For Decision Tree:\",classification_report(y_test, y_pred2)) "
      ],
      "id": "Ohaqx-jyRZxE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjK8w0s0CSw1",
        "outputId": "d1643fa4-2438-4905-f4be-aea583911144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[ 5  0  0 ...  0  0  0]\n",
            " [ 0  6  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 0  0  0 ...  0  0  9]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred2))"
      ],
      "id": "kjK8w0s0CSw1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79NPc6iBNKur"
      },
      "outputs": [],
      "source": [
        "#SVm\n",
        "from sklearn.svm import SVC\n",
        "acc_values = []\n",
        "for item in ['linear','poly','rbf']:\n",
        "    svm_classifier = SVC(kernel=item)\n",
        "    svm_classifier.fit(X_train,y_train)\n",
        "    y_pred3 = svm_classifier.predict(X_test)\n",
        "    acc = accuracy_score(y_test,y_pred3)\n",
        "    acc_values.append(acc)"
      ],
      "id": "79NPc6iBNKur"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxxsMvZbNie3",
        "outputId": "886be604-3f29-47fe-e087-f2e1e0c8f390"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7046666666666667, 0.5636666666666666, 0.6506666666666666]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "acc_values"
      ],
      "id": "XxxsMvZbNie3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNjagQZVP4on"
      },
      "source": [
        "linear kernel provides best result"
      ],
      "id": "DNjagQZVP4on"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRgBQnZcCSzc"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm_linear=SVC(kernel='linear')\n",
        "svm_linear.fit(X_train,y_train)\n",
        "y_pred3=svm_linear.predict(X_test)"
      ],
      "id": "MRgBQnZcCSzc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gCxm5lrRhu4",
        "outputId": "4380b121-c955-4ff9-ccb7-f749aa03249d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for SVM:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           9       0.45      0.45      0.45        11\n",
            "          10       0.00      0.00      0.00        12\n",
            "          11       0.00      0.00      0.00         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         4\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         2\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       0.21      1.00      0.35        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          39       0.50      0.60      0.55         5\n",
            "          41       0.00      0.00      0.00         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       0.24      0.60      0.34        43\n",
            "          48       0.00      0.00      0.00         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         6\n",
            "          53       0.00      0.00      0.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       0.08      0.22      0.12         9\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.67      0.67      0.67         3\n",
            "          65       0.00      0.00      0.00         2\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         4\n",
            "          70       0.00      0.00      0.00         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       0.00      0.00      0.00         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       0.00      0.00      0.00        31\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.33      0.78      0.47        54\n",
            "          81       0.00      0.00      0.00        35\n",
            "          83       0.00      0.00      0.00        54\n",
            "          84       0.00      0.00      0.00        13\n",
            "          86       0.50      0.68      0.57       105\n",
            "          87       0.00      0.00      0.00        22\n",
            "          88       0.70      0.93      0.80       108\n",
            "          89       0.09      0.33      0.14        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       0.00      0.00      0.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          95       0.00      0.00      0.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       0.00      0.00      0.00         2\n",
            "          98       0.00      0.00      0.00         4\n",
            "          99       0.00      0.00      0.00         6\n",
            "         100       0.00      0.00      0.00         6\n",
            "         101       0.00      0.00      0.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       0.03      0.04      0.03        25\n",
            "         106       0.00      0.00      0.00        39\n",
            "         107       0.45      0.67      0.54        66\n",
            "         108       0.19      0.06      0.10        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.00      0.00      0.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.00      0.00      0.00         6\n",
            "         114       0.00      0.00      0.00         1\n",
            "         115       0.00      0.00      0.00         2\n",
            "         116       0.00      0.00      0.00        36\n",
            "         117       0.00      0.00      0.00         2\n",
            "         118       0.27      0.83      0.41        54\n",
            "         119       0.32      0.58      0.42        43\n",
            "         120       0.88      0.96      0.92       128\n",
            "         121       0.00      0.00      0.00         5\n",
            "         122       0.00      0.00      0.00        72\n",
            "         123       0.00      0.00      0.00        24\n",
            "         124       0.96      0.88      0.92       137\n",
            "         125       0.00      0.00      0.00         2\n",
            "         126       0.00      0.00      0.00         5\n",
            "         127       0.00      0.00      0.00        14\n",
            "         128       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.70      3000\n",
            "   macro avg       0.11      0.14      0.12      3000\n",
            "weighted avg       0.65      0.70      0.67      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report for SVM:\",classification_report(y_test, y_pred3)) "
      ],
      "id": "7gCxm5lrRhu4"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao4fmqYXaXyA",
        "outputId": "756d2d0c-485d-481f-d566-99243e0bf4c8"
      },
      "id": "ao4fmqYXaXyA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAZWK9GHCS37"
      },
      "outputs": [],
      "source": [
        "#Random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred4=rf.predict(X_test)"
      ],
      "id": "BAZWK9GHCS37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8hoNfGRMOa",
        "outputId": "b7e04350-96bb-40db-94fe-c64577402316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Random forest:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.80      0.50      0.62         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       1.00      1.00      1.00        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.25      0.67      0.36         3\n",
            "          12       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         1\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.25      1.00      0.40         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.50      1.00      0.67         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       1.00      1.00      1.00         5\n",
            "          41       0.75      0.75      0.75         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       1.00      1.00      1.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      0.50      0.67         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       0.86      1.00      0.92         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       1.00      1.00      1.00         2\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      0.90      0.95        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          62       0.00      0.00      0.00         0\n",
            "          64       0.75      1.00      0.86         3\n",
            "          65       0.40      1.00      0.57         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.67      0.50      0.57         4\n",
            "          70       0.83      0.83      0.83         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.00      0.00      0.00         0\n",
            "          75       1.00      0.75      0.86         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       1.00      1.00      1.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         0\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       0.75      1.00      0.86         6\n",
            "         100       0.86      1.00      0.92         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         103       0.00      0.00      0.00         0\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       1.00      1.00      1.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       0.50      1.00      0.67         1\n",
            "         115       1.00      0.50      0.67         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       0.83      1.00      0.91         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       1.00      0.89      0.94         9\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.65      0.68      0.65      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report for Random forest:\",classification_report(y_test, y_pred4)) "
      ],
      "id": "wK8hoNfGRMOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4PGH-xSOHNr",
        "outputId": "5ffde3ff-28fc-4547-b7da-becd628c5785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[ 4  0  0 ...  0  0  0]\n",
            " [ 0  6  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 0  0  0 ...  0  0  8]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\",confusion_matrix(y_test,y_pred4))"
      ],
      "id": "K4PGH-xSOHNr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCgD1qRVMP7N"
      },
      "source": [
        "# Fine Tuning"
      ],
      "id": "wCgD1qRVMP7N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXhUYqjmOHQ1"
      },
      "outputs": [],
      "source": [
        "#Random forest\n",
        "model_parameters = {'n_estimators': [50, 100, 200, 400, 500, 700, 900],\n",
        "               'criterion': ['gini', 'entropy'],\n",
        "               'max_features': ['auto', 'sqrt', 'log2'],\n",
        "               'max_depth': [None],\n",
        "               'min_samples_split': [2, 5, 10],\n",
        "               'min_samples_leaf': [1, 2, 4],\n",
        "               'bootstrap': [True, False]}"
      ],
      "id": "CXhUYqjmOHQ1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxkKBwArOHUO",
        "outputId": "35dad021-5f66-4338-9954-8bf23567c765"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'criterion': ['gini', 'entropy'],\n",
              "                                        'max_depth': [None],\n",
              "                                        'max_features': ['auto', 'sqrt',\n",
              "                                                         'log2'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200, 400, 500,\n",
              "                                                         700, 900]},\n",
              "                   random_state=42, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "\n",
        "rf_search = RandomizedSearchCV(estimator = model, \n",
        "                               param_distributions = model_parameters, \n",
        "                               n_iter = 100, \n",
        "                               cv = 3, \n",
        "                               verbose=2, \n",
        "                               random_state=42, \n",
        "                               n_jobs = -1)\n",
        "\n",
        "rf_search.fit(X_train, y_train)"
      ],
      "id": "uxkKBwArOHUO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vAUJzhmUQ-C",
        "outputId": "89ab52f4-74ca-4494-d6f3-48e4de4a2bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'criterion': 'entropy',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 400}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "rf_search.best_params_"
      ],
      "id": "_vAUJzhmUQ-C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kKDQKqYURIy"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(**rf_search.best_params_)\n",
        "rf_classifier.fit(X_train,y_train)\n",
        "y_pred = rf_classifier.predict(X_test)"
      ],
      "id": "1kKDQKqYURIy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDgDbQJRURLS",
        "outputId": "af00b089-1eee-46c3-ae39-721c26b1b378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for test data is : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.80      0.50      0.62         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       1.00      1.00      1.00        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.25      0.67      0.36         3\n",
            "          12       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         1\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.25      1.00      0.40         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.50      1.00      0.67         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          39       1.00      1.00      1.00         5\n",
            "          41       0.75      0.75      0.75         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       1.00      1.00      1.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      0.50      0.67         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       0.86      1.00      0.92         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       1.00      1.00      1.00         2\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      0.90      0.95        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          62       0.00      0.00      0.00         0\n",
            "          63       0.00      0.00      0.00         0\n",
            "          64       0.75      1.00      0.86         3\n",
            "          65       0.40      1.00      0.57         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.67      0.50      0.57         4\n",
            "          70       0.83      0.83      0.83         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.00      0.00      0.00         0\n",
            "          75       1.00      0.75      0.86         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       1.00      1.00      1.00         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       1.00      1.00      1.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         0\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       0.75      1.00      0.86         6\n",
            "         100       0.86      1.00      0.92         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         103       0.00      0.00      0.00         0\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       1.00      1.00      1.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       0.50      1.00      0.67         1\n",
            "         115       1.00      0.50      0.67         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       1.00      1.00      1.00         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       1.00      0.89      0.94         9\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.65      0.68      0.65      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Classification report for test data is : \\n',\n",
        "      classification_report(y_test, y_pred))"
      ],
      "id": "sDgDbQJRURLS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4GwMXqzZvCB"
      },
      "source": [
        "We can see that it didn't  make a difference"
      ],
      "id": "X4GwMXqzZvCB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q6pjypDURO_"
      },
      "outputs": [],
      "source": [
        "#logistic regression\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "model_parameters = {'penalty':penalty,'solver':solvers,'C':c_values}"
      ],
      "id": "1q6pjypDURO_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_L_6h0VHit",
        "outputId": "76feed73-0b41-4c7a-d776-79416fed3859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=0, estimator=LogisticRegression(), n_jobs=-1,\n",
              "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01], 'penalty': ['l2'],\n",
              "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "model = LogisticRegression()\n",
        "logReg_search = GridSearchCV(estimator=model, param_grid=model_parameters, n_jobs=-1, cv=3, scoring='accuracy',error_score=0)\n",
        "logReg_search.fit(X_test,y_test)"
      ],
      "id": "CG_L_6h0VHit"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt8Ms-MaVHlp",
        "outputId": "f003f591-2d6c-4772-af9f-6bf242070735"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "logReg_search.best_params_"
      ],
      "id": "rt8Ms-MaVHlp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a16yGjJRVHox"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(**logReg_search.best_params_)\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "id": "a16yGjJRVHox"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XAF179yVHsH",
        "outputId": "13bf5a89-b26b-4ba5-efeb-eecd728f13eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for test data is : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.25      0.14      0.18         7\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           9       0.45      0.45      0.45        11\n",
            "          10       0.00      0.00      0.00        12\n",
            "          11       0.00      0.00      0.00         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.22      1.00      0.36         4\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       0.56      1.00      0.72        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          39       0.60      0.60      0.60         5\n",
            "          41       0.00      0.00      0.00         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       0.72      0.91      0.80        43\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       0.00      0.00      0.00         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         6\n",
            "          53       0.00      0.00      0.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       0.07      0.22      0.11         9\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          61       0.00      0.00      0.00         0\n",
            "          64       0.50      0.67      0.57         3\n",
            "          65       0.00      0.00      0.00         2\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         4\n",
            "          70       0.00      0.00      0.00         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       0.00      0.00      0.00         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       0.00      0.00      0.00        31\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.60      0.69      0.64        54\n",
            "          81       0.06      0.03      0.04        35\n",
            "          83       0.81      0.48      0.60        54\n",
            "          84       0.30      1.00      0.46        13\n",
            "          86       0.86      0.68      0.76       105\n",
            "          87       0.00      0.00      0.00        22\n",
            "          88       0.70      0.93      0.80       108\n",
            "          89       0.10      0.33      0.15        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       0.00      0.00      0.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          95       0.00      0.00      0.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       0.00      0.00      0.00         2\n",
            "          98       0.00      0.00      0.00         4\n",
            "          99       0.00      0.00      0.00         6\n",
            "         100       0.25      0.33      0.29         6\n",
            "         101       0.40      0.17      0.24        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       0.41      0.88      0.56        25\n",
            "         106       0.14      0.23      0.17        39\n",
            "         107       0.52      0.67      0.58        66\n",
            "         108       0.75      0.83      0.79        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.00      0.00      0.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.00      0.00      0.00         6\n",
            "         114       0.00      0.00      0.00         1\n",
            "         115       0.00      0.00      0.00         2\n",
            "         116       0.00      0.00      0.00        36\n",
            "         117       0.33      1.00      0.50         2\n",
            "         118       0.64      0.83      0.73        54\n",
            "         119       0.37      0.72      0.49        43\n",
            "         120       0.88      0.96      0.92       128\n",
            "         121       0.00      0.00      0.00         5\n",
            "         122       0.59      0.18      0.28        72\n",
            "         123       0.00      0.00      0.00        24\n",
            "         124       0.96      0.88      0.92       137\n",
            "         125       0.00      0.00      0.00         2\n",
            "         126       0.00      0.00      0.00         5\n",
            "         127       0.38      0.43      0.40        14\n",
            "         128       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.76      3000\n",
            "   macro avg       0.17      0.20      0.17      3000\n",
            "weighted avg       0.74      0.76      0.74      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Classification report for test data is : \\n',\n",
        "      classification_report(y_test, y_pred))"
      ],
      "id": "8XAF179yVHsH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bplcx2JzaAbv"
      },
      "source": [
        "In logistic regression we can see a 22% increase in accuracy after hyperparameter tuning"
      ],
      "id": "Bplcx2JzaAbv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QzDUDLMam3_"
      },
      "outputs": [],
      "source": [
        "#Decision tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'max_depth': [2, 3, 5, 10, 20],\n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
        "    'criterion': [\"gini\", \"entropy\"]\n",
        "}"
      ],
      "id": "7QzDUDLMam3_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ujb5lXSXlm",
        "outputId": "5dffedcf-6afc-499c-c0b0-268c0030095b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [2, 3, 5, 10, 20],\n",
              "                         'min_samples_leaf': [5, 10, 20, 50, 100]},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=data_model, \n",
        "                           param_grid=params, \n",
        "                           cv=4, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "id": "X8Ujb5lXSXlm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6V5z-RISXou",
        "outputId": "68f655cc-b97d-42c9-9bc9-1ef1503ddeac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=20, min_samples_leaf=5)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "grid_search.best_estimator_"
      ],
      "id": "Z6V5z-RISXou"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PlVSJEh1XF5",
        "outputId": "a2a8d79c-13f4-4964-8dad-0486e8485999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       0.25      1.00      0.40         1\n",
            "           3       0.80      0.50      0.62         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.50      1.00      0.67         3\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       1.00      1.00      1.00        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.30      1.00      0.46         3\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.50      1.00      0.67         1\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.25      1.00      0.40         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.25      1.00      0.40         2\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          37       0.00      0.00      0.00         0\n",
            "          39       1.00      1.00      1.00         5\n",
            "          41       1.00      1.00      1.00         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       1.00      1.00      1.00         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.00      0.00      0.00         1\n",
            "          58       1.00      1.00      1.00        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       0.33      1.00      0.50         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         4\n",
            "          70       0.00      0.00      0.00         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.20      1.00      0.33         1\n",
            "          75       0.00      0.00      0.00         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       1.00      1.00      1.00         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       1.00      1.00      1.00         6\n",
            "         100       1.00      1.00      1.00         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.43      1.00      0.60         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       1.00      1.00      1.00         1\n",
            "         115       1.00      1.00      1.00         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       1.00      1.00      1.00         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       0.29      1.00      0.44         2\n",
            "         126       1.00      1.00      1.00         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.58      0.64      0.59      3000\n",
            "weighted avg       0.97      0.98      0.97      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "grid_search_predictions = grid_search.predict(X_test)\n",
        "print(classification_report(y_test,grid_search_predictions))"
      ],
      "id": "4PlVSJEh1XF5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr01FHIJ1Hjc",
        "outputId": "073116e7-45b5-4bfc-950a-dc6d98499816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  0  0 ...  0  0  0]\n",
            " [ 0  6  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 0  0  0 ...  0  0  9]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test,grid_search_predictions))"
      ],
      "id": "fr01FHIJ1Hjc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMLKLTUl2t_D"
      },
      "source": [
        "We can see that it didn't make much difference"
      ],
      "id": "rMLKLTUl2t_D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhVg6Ansaqfm"
      },
      "outputs": [],
      "source": [
        "#KNN\n",
        "grid_params = { 'n_neighbors' : [3,5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}"
      ],
      "id": "zhVg6Ansaqfm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiaygVX1byVd",
        "outputId": "3715a64b-8d3f-40bd-a882-4fffcb839db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
        "g_res = gs.fit(X_train, y_train)"
      ],
      "id": "AiaygVX1byVd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57IcPK9EfVxk",
        "outputId": "c1130ed0-8dcf-47e3-dd9f-ad30ae804ef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "g_res.best_params_"
      ],
      "id": "57IcPK9EfVxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCIbZJjb0kA9",
        "outputId": "516bfab1-281d-407d-d29d-3912a5e0319f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.33      0.14      0.20         7\n",
            "           2       0.33      1.00      0.50         1\n",
            "           3       0.50      0.75      0.60         8\n",
            "           5       0.67      0.67      0.67         6\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.50      1.00      0.67         3\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.70      0.64      0.67        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.33      0.33      0.33         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         1\n",
            "          23       0.50      1.00      0.67         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       1.00      1.00      1.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          33       1.00      1.00      1.00         3\n",
            "          34       0.00      0.00      0.00         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       0.80      0.80      0.80         5\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       1.00      1.00      1.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.50      0.50      0.50         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          48       0.86      1.00      0.92         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      0.90      0.95        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       0.50      1.00      0.67         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       1.00      1.00      1.00         1\n",
            "          69       0.50      0.50      0.50         4\n",
            "          70       0.83      0.83      0.83         6\n",
            "          72       0.00      0.00      0.00         1\n",
            "          75       1.00      0.75      0.86         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       1.00      1.00      1.00        31\n",
            "          79       0.50      1.00      0.67         1\n",
            "          80       1.00      1.00      1.00        54\n",
            "          81       1.00      1.00      1.00        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       0.89      1.00      0.94         8\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         0\n",
            "          95       1.00      1.00      1.00         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       0.86      1.00      0.92         6\n",
            "         100       0.86      1.00      0.92         6\n",
            "         101       1.00      1.00      1.00        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         103       0.00      0.00      0.00         0\n",
            "         104       1.00      1.00      1.00        25\n",
            "         106       1.00      1.00      1.00        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       1.00      1.00      1.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       1.00      1.00      1.00         6\n",
            "         114       0.50      1.00      0.67         1\n",
            "         115       0.50      0.50      0.50         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      1.00      1.00        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       1.00      1.00      1.00         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       1.00      1.00      1.00         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       1.00      0.89      0.94         9\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.65      0.68      0.65      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "g_res_predictions = g_res.predict(X_test)\n",
        "print(classification_report(y_test,g_res_predictions))"
      ],
      "id": "RCIbZJjb0kA9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KNADVGZ00hR",
        "outputId": "a4f1c8a7-9677-4ea1-e661-e7464c106332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  0  0 ...  0  0  0]\n",
            " [ 0  1  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 0  0  0 ...  0  0  8]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test,g_res_predictions))"
      ],
      "id": "2KNADVGZ00hR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hSuFLh42nDT"
      },
      "source": [
        "We can see that it didn't make a difference"
      ],
      "id": "5hSuFLh42nDT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kef3nlspgHH6"
      },
      "outputs": [],
      "source": [
        "#SVM\n",
        "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
      ],
      "id": "kef3nlspgHH6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfIQ9cuRgHKQ",
        "outputId": "eab5354b-d5bd-4a03-febf-415eda0fecf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   1.2s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   1.2s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   1.1s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   1.1s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   1.2s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   3.4s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   3.4s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   3.4s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   3.4s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   3.4s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.4s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.3s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.4s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.3s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.4s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   2.4s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   2.4s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   2.5s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   3.0s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   2.9s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   3.5s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   2.8s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   2.9s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   3.5s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   3.6s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   3.5s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   3.5s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   3.7s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   2.7s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   2.7s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   3.6s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   3.6s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   3.5s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   3.5s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   3.5s\n",
            "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   2.6s\n",
            "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   3.6s\n",
            "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   3.6s\n",
            "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   3.7s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   2.1s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.5s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   1.0s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   1.0s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   2.9s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   2.9s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   2.8s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   2.8s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   2.9s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.8s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.8s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.8s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.7s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.8s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   2.0s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   2.0s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   2.0s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   1.9s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   2.0s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   2.1s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   2.3s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   2.3s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   2.3s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   2.3s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   2.3s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.2s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.6s\n",
            "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   3.8s\n",
            "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   3.8s\n",
            "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   3.8s\n",
            "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   3.6s\n",
            "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   3.8s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.1s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.1s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.1s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.1s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.1s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.9s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.5s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.4s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.4s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   1.6s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   1.6s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   1.6s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   1.5s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   1.6s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   1.6s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   1.6s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   1.6s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   1.5s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   1.6s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   2.1s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   2.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   2.5s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   2.5s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   2.5s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   2.4s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   2.4s\n",
            "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   2.6s\n",
            "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   2.6s\n",
            "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   2.7s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.8s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.8s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.8s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.8s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.8s\n",
            "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.8s\n",
            "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   2.6s\n",
            "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   2.5s\n",
            "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   2.5s\n",
            "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   2.5s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.3s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.2s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.2s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.2s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.2s\n",
            "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   1.2s\n",
            "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   1.2s\n",
            "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   1.2s\n",
            "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   1.2s\n",
            "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   1.2s\n",
            "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
            "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
            "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
            "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
            "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   1.8s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   1.7s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   1.7s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   1.7s\n",
            "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   2.6s\n",
            "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   2.5s\n",
            "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
            "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
            "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   1.8s\n",
            "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
            "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   2.1s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   2.1s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   2.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   2.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   2.1s\n",
            "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   2.6s\n",
            "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   2.5s\n",
            "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   1.8s\n",
            "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   1.8s\n",
            "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   1.8s\n",
            "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   1.8s\n",
            "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   1.8s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
              "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
        "grid.fit(X_train,y_train)"
      ],
      "id": "KfIQ9cuRgHKQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPUC1IX9z_Fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf418c6-56d2-40d5-8b95-0abf99dcafb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, gamma=1, kernel='poly')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "grid.best_estimator_"
      ],
      "id": "gPUC1IX9z_Fh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2G_CsZV0PI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2045da-c0fa-478f-b447-2cacfa0b5236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.80      0.53         5\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.75      0.38      0.50         8\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       1.00      0.33      0.50         3\n",
            "           7       0.00      0.00      0.00         3\n",
            "           9       1.00      0.73      0.84        11\n",
            "          10       1.00      1.00      1.00        12\n",
            "          11       0.20      0.33      0.25         3\n",
            "          12       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.40      1.00      0.57         4\n",
            "          22       0.50      1.00      0.67         1\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.25      1.00      0.40         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.50      1.00      0.67         3\n",
            "          35       1.00      1.00      1.00        38\n",
            "          36       0.00      0.00      0.00         3\n",
            "          39       0.80      0.80      0.80         5\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       1.00      1.00      1.00        43\n",
            "          48       0.83      0.83      0.83         6\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       1.00      1.00      1.00         2\n",
            "          52       1.00      1.00      1.00         6\n",
            "          53       1.00      1.00      1.00        48\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      1.00      1.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          58       1.00      0.90      0.95        10\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "          63       0.00      0.00      0.00         0\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       0.25      1.00      0.40         2\n",
            "          66       0.40      1.00      0.57         2\n",
            "          67       0.00      0.00      0.00         1\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.50      0.50      0.50         4\n",
            "          70       0.83      0.83      0.83         6\n",
            "          71       0.00      0.00      0.00         0\n",
            "          72       0.50      1.00      0.67         1\n",
            "          75       1.00      0.75      0.86         4\n",
            "          76       0.00      0.00      0.00         1\n",
            "          77       1.00      1.00      1.00       220\n",
            "          78       0.87      0.65      0.74        31\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.86      1.00      0.92        54\n",
            "          81       0.79      0.97      0.87        35\n",
            "          83       1.00      1.00      1.00        54\n",
            "          84       1.00      1.00      1.00        13\n",
            "          86       1.00      1.00      1.00       105\n",
            "          87       1.00      1.00      1.00        22\n",
            "          88       1.00      1.00      1.00       108\n",
            "          89       1.00      1.00      1.00        15\n",
            "          90       1.00      1.00      1.00       170\n",
            "          91       1.00      0.25      0.40         8\n",
            "          92       0.00      0.00      0.00         0\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         0\n",
            "          95       0.40      1.00      0.57         4\n",
            "          96       1.00      1.00      1.00       657\n",
            "          97       0.20      1.00      0.33         2\n",
            "          98       1.00      0.75      0.86         4\n",
            "          99       0.57      0.67      0.62         6\n",
            "         100       0.33      0.33      0.33         6\n",
            "         101       0.68      1.00      0.81        23\n",
            "         102       1.00      1.00      1.00       409\n",
            "         104       1.00      0.88      0.94        25\n",
            "         106       0.97      0.77      0.86        39\n",
            "         107       1.00      1.00      1.00        66\n",
            "         108       1.00      1.00      1.00        78\n",
            "         110       0.00      0.00      0.00         1\n",
            "         111       0.00      0.00      0.00         3\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.67      1.00      0.80         6\n",
            "         114       0.50      1.00      0.67         1\n",
            "         115       0.50      0.50      0.50         2\n",
            "         116       1.00      1.00      1.00        36\n",
            "         117       1.00      1.00      1.00         2\n",
            "         118       1.00      1.00      1.00        54\n",
            "         119       1.00      0.79      0.88        43\n",
            "         120       1.00      1.00      1.00       128\n",
            "         121       0.60      0.60      0.60         5\n",
            "         122       1.00      1.00      1.00        72\n",
            "         123       1.00      1.00      1.00        24\n",
            "         124       1.00      1.00      1.00       137\n",
            "         125       1.00      1.00      1.00         2\n",
            "         126       0.56      1.00      0.71         5\n",
            "         127       1.00      1.00      1.00        14\n",
            "         128       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.96      3000\n",
            "   macro avg       0.55      0.60      0.56      3000\n",
            "weighted avg       0.96      0.96      0.95      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "grid_predictions = grid.predict(X_test)\n",
        "print(classification_report(y_test,grid_predictions))"
      ],
      "id": "_2G_CsZV0PI-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUKioGZy0bY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94ff2f4-b473-43da-84f6-dd1abfc63d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  0  0 ...  0  0  0]\n",
            " [ 0  6  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  0 ...  0 14  0]\n",
            " [ 5  0  0 ...  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test,grid_predictions))"
      ],
      "id": "sUKioGZy0bY9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i66ay7972VbC"
      },
      "source": [
        "In svm we can see a 26% increase in accuracy after hyperparameter tuning"
      ],
      "id": "i66ay7972VbC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xZqW4fX21IV"
      },
      "source": [
        "# Result"
      ],
      "id": "_xZqW4fX21IV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaWEIxL-34-t"
      },
      "source": [
        "we can conclude that decision tree,random forest and knn have the largest estimated accuracy score(99%). Logestic regression has the worst."
      ],
      "id": "YaWEIxL-34-t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NvesE6E37Bq"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "2NvesE6E37Bq"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final_project(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
